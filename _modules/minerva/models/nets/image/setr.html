

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>minerva.models.nets.image.setr &mdash; minerva  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/graphviz.css?v=4ae1632d" />

  
      <script src="../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../index.html" class="icon icon-home">
            minerva
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../design.html">Minerva Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials.html">Examples and Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../contributing.html">Contributing to Minerva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../api.html">Programming Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">minerva</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">minerva.models.nets.image.setr</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for minerva.models.nets.image.setr</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">lightning.pytorch</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">L</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim.adam</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchmetrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">Metric</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">minerva.engines.engine</span><span class="w"> </span><span class="kn">import</span> <span class="n">_Engine</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">minerva.models.nets.image.vit</span><span class="w"> </span><span class="kn">import</span> <span class="n">_VisionTransformerBackbone</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">minerva.utils.upsample</span><span class="w"> </span><span class="kn">import</span> <span class="n">Upsample</span>


<div class="viewcode-block" id="_SETRUPHead">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/image/setr/index.html#minerva.models.nets.image.setr._SETRUPHead">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">_SETRUPHead</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Naive upsampling head and Progressive upsampling head of SETR</span>
<span class="sd">    (as in https://arxiv.org/pdf/2012.15840.pdf).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">norm_layer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">conv_norm</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">conv_act</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">num_convs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">up_scale</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">align_corners</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">interpolate_mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The SETR PUP Head.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        channels : int</span>
<span class="sd">            Number of output channels.</span>
<span class="sd">        in_channels : int</span>
<span class="sd">            Number of input channels.</span>
<span class="sd">        num_classes : int</span>
<span class="sd">            Number of output classes.</span>
<span class="sd">        norm_layer : nn.Module</span>
<span class="sd">            Normalization layer.</span>
<span class="sd">        conv_norm : nn.Module</span>
<span class="sd">            Convolutional normalization layer.</span>
<span class="sd">        conv_act : nn.Module</span>
<span class="sd">            Convolutional activation layer.</span>
<span class="sd">        num_convs : int</span>
<span class="sd">            Number of convolutional layers.</span>
<span class="sd">        up_scale : int</span>
<span class="sd">            Upsampling scale factor.</span>
<span class="sd">        kernel_size : int</span>
<span class="sd">            Kernel size for convolutional layers.</span>
<span class="sd">        align_corners : bool</span>
<span class="sd">            Whether to align corners during upsampling.</span>
<span class="sd">        dropout : float</span>
<span class="sd">            Dropout rate.</span>
<span class="sd">        interpolate_mode : str</span>
<span class="sd">            Interpolation mode for upsampling.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        AssertionError</span>
<span class="sd">            If kernel_size is not 1 or 3.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">kernel_size</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="s2">&quot;kernel_size must be 1 or 3.&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cls_seg</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">norm_layer</span>
        <span class="n">conv_norm</span> <span class="o">=</span> <span class="n">conv_norm</span>
        <span class="n">conv_act</span> <span class="o">=</span> <span class="n">conv_act</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span> <span class="k">if</span> <span class="n">dropout</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="o">!=</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">up_convs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_convs</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">up_convs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
                        <span class="n">in_channels</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span>
                        <span class="n">kernel_size</span><span class="p">,</span>
                        <span class="n">padding</span><span class="o">=</span><span class="n">kernel_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                        <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="n">conv_norm</span><span class="p">,</span>
                    <span class="n">conv_act</span><span class="p">,</span>
                    <span class="n">Upsample</span><span class="p">(</span>
                        <span class="n">scale_factor</span><span class="o">=</span><span class="n">up_scale</span><span class="p">,</span>
                        <span class="n">mode</span><span class="o">=</span><span class="n">interpolate_mode</span><span class="p">,</span>
                        <span class="n">align_corners</span><span class="o">=</span><span class="n">align_corners</span><span class="p">,</span>
                    <span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="n">in_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span>

<div class="viewcode-block" id="_SETRUPHead.forward">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/image/setr/index.html#minerva.models.nets.image.setr._SETRUPHead.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span> <span class="o">*</span> <span class="n">w</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">up_conv</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_convs</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">up_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls_seg</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span></div>
</div>



<div class="viewcode-block" id="_SETRMLAHead">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/image/setr/index.html#minerva.models.nets.image.setr._SETRMLAHead">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">_SETRMLAHead</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multi level feature aggretation head of SETR (as in</span>
<span class="sd">    https://arxiv.org/pdf/2012.15840.pdf)</span>

<span class="sd">    Note: This has not been tested yet!</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">conv_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">],</span>
        <span class="n">conv_act</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">],</span>
        <span class="n">in_channels</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">mla_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
        <span class="n">up_scale</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">align_corners</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">threshold</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">out_channels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">num_classes</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;For binary segmentation, we suggest using&quot;</span>
                    <span class="s2">&quot;`out_channels = 1` to define the output&quot;</span>
                    <span class="s2">&quot;channels of segmentor, and use `threshold`&quot;</span>
                    <span class="s2">&quot;to convert `seg_logits` into a prediction&quot;</span>
                    <span class="s2">&quot;applying a threshold&quot;</span>
                <span class="p">)</span>
            <span class="n">out_channels</span> <span class="o">=</span> <span class="n">num_classes</span>

        <span class="k">if</span> <span class="n">out_channels</span> <span class="o">!=</span> <span class="n">num_classes</span> <span class="ow">and</span> <span class="n">out_channels</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;out_channels should be equal to num_classes,&quot;</span>
                <span class="s2">&quot;except binary segmentation set out_channels == 1 and&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;num_classes == 2, but got out_channels=</span><span class="si">{</span><span class="n">out_channels</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;and num_classes=</span><span class="si">{</span><span class="n">num_classes</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">out_channels</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">threshold</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.3</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;threshold is not defined for binary, and defaults to 0.3&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">threshold</span>
        <span class="n">conv_norm</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">conv_norm</span> <span class="k">if</span> <span class="n">conv_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">SyncBatchNorm</span><span class="p">(</span><span class="n">mla_channels</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">conv_act</span> <span class="o">=</span> <span class="n">conv_act</span> <span class="k">if</span> <span class="n">conv_act</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span> <span class="k">if</span> <span class="n">dropout</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="o">!=</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cls_seg</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">num_inputs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">in_channels</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">up_convs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">up_convs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
                        <span class="n">in_channels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                        <span class="n">mla_channels</span><span class="p">,</span>
                        <span class="n">kernel_size</span><span class="p">,</span>
                        <span class="n">padding</span><span class="o">=</span><span class="n">kernel_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                        <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="n">conv_norm</span><span class="p">,</span>
                    <span class="n">conv_act</span><span class="p">,</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
                        <span class="n">mla_channels</span><span class="p">,</span>
                        <span class="n">mla_channels</span><span class="p">,</span>
                        <span class="n">kernel_size</span><span class="p">,</span>
                        <span class="n">padding</span><span class="o">=</span><span class="n">kernel_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                        <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="n">conv_norm</span><span class="p">,</span>
                    <span class="n">conv_act</span><span class="p">,</span>
                    <span class="n">Upsample</span><span class="p">(</span>
                        <span class="n">scale_factor</span><span class="o">=</span><span class="n">up_scale</span><span class="p">,</span>
                        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span>
                        <span class="n">align_corners</span><span class="o">=</span><span class="n">align_corners</span><span class="p">,</span>
                    <span class="p">),</span>
                <span class="p">)</span>
            <span class="p">)</span>

<div class="viewcode-block" id="_SETRMLAHead.forward">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/image/setr/index.html#minerva.models.nets.image.setr._SETRMLAHead.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">up_conv</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_convs</span><span class="p">):</span>
            <span class="n">outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">up_conv</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cls_seg</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span></div>
</div>



<div class="viewcode-block" id="_SetR_PUP">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/image/setr/index.html#minerva.models.nets.image.setr._SetR_PUP">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">_SetR_PUP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span>
        <span class="n">patch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_convs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">decoder_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">up_scale</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">encoder_dropout</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">decoder_dropout</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">norm_layer</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">interpolate_mode</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">conv_norm</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">conv_act</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">align_corners</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">aux_output</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
        <span class="n">aux_output_layers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
        <span class="n">original_resolution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initializes the SETR PUP head.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image_size : int or Tuple[int, int]</span>
<span class="sd">            The size of the input image.</span>
<span class="sd">        patch_size : int</span>
<span class="sd">            The size of each patch in the input image.</span>
<span class="sd">        num_layers : int</span>
<span class="sd">            The number of layers in the transformer encoder.</span>
<span class="sd">        num_heads : int</span>
<span class="sd">            The number of attention heads in the transformer encoder.</span>
<span class="sd">        hidden_dim : int</span>
<span class="sd">            The hidden dimension of the transformer encoder.</span>
<span class="sd">        mlp_dim : int</span>
<span class="sd">            The dimension of the feed-forward network in the transformer encoder</span>
<span class="sd">        num_convs : int</span>
<span class="sd">            The number of convolutional layers in the decoder.</span>
<span class="sd">        num_classes : int</span>
<span class="sd">            The number of output classes.</span>
<span class="sd">        decoder_channels : int</span>
<span class="sd">            The number of channels in the decoder.</span>
<span class="sd">        up_scale : int</span>
<span class="sd">            The scale factor for upsampling in the decoder.</span>
<span class="sd">        encoder_dropout : float</span>
<span class="sd">            The dropout rate for the transformer encoder.</span>
<span class="sd">        kernel_size : int</span>
<span class="sd">            The kernel size for the convolutional layers in the decoder.</span>
<span class="sd">        decoder_dropout : float</span>
<span class="sd">            The dropout rate for the decoder.</span>
<span class="sd">        norm_layer : nn.Module</span>
<span class="sd">            The normalization layer to be used.</span>
<span class="sd">        interpolate_mode : str</span>
<span class="sd">            The mode for interpolation during upsampling.</span>
<span class="sd">        conv_norm : nn.Module</span>
<span class="sd">            The normalization layer to be used in the decoder convolutional</span>
<span class="sd">            layers.</span>
<span class="sd">        conv_act : nn.Module</span>
<span class="sd">            The activation function to be used in the decoder convolutional</span>
<span class="sd">            layers.</span>
<span class="sd">        align_corners : bool</span>
<span class="sd">            Whether to align corners during upsampling.</span>
<span class="sd">        aux_output: bool</span>
<span class="sd">            Whether to use auxiliary outputs. If True, aux_output_layers must</span>
<span class="sd">            be provided.</span>
<span class="sd">        aux_output_layers: List[int], optional</span>
<span class="sd">            The layers to use for auxiliary outputs. Must have exacly 3 values.</span>
<span class="sd">        original_resolution: Tuple[int, int], optional</span>
<span class="sd">            The original resolution of the input image in the pre-training</span>
<span class="sd">            weights. When None, positional embeddings will not be interpolated.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">aux_output</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">aux_output_layers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;aux_output_layers must be provided.&quot;</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">aux_output_layers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
            <span class="p">),</span> <span class="s2">&quot;aux_output_layers must have 3 values. Only 3 aux heads are supported.&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">aux_output</span> <span class="o">=</span> <span class="n">aux_output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aux_output_layers</span> <span class="o">=</span> <span class="n">aux_output_layers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">_VisionTransformerBackbone</span><span class="p">(</span>
            <span class="n">image_size</span><span class="o">=</span><span class="n">image_size</span><span class="p">,</span>
            <span class="n">patch_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
            <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
            <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span>
            <span class="n">mlp_dim</span><span class="o">=</span><span class="n">mlp_dim</span><span class="p">,</span>
            <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">encoder_dropout</span><span class="p">,</span>
            <span class="n">aux_output</span><span class="o">=</span><span class="n">aux_output</span><span class="p">,</span>
            <span class="n">aux_output_layers</span><span class="o">=</span><span class="n">aux_output_layers</span><span class="p">,</span>
            <span class="n">original_resolution</span><span class="o">=</span><span class="n">original_resolution</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">_SETRUPHead</span><span class="p">(</span>
            <span class="n">channels</span><span class="o">=</span><span class="n">decoder_channels</span><span class="p">,</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span>
            <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
            <span class="n">num_convs</span><span class="o">=</span><span class="n">num_convs</span><span class="p">,</span>
            <span class="n">up_scale</span><span class="o">=</span><span class="n">up_scale</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">align_corners</span><span class="o">=</span><span class="n">align_corners</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">decoder_dropout</span><span class="p">,</span>
            <span class="n">conv_norm</span><span class="o">=</span><span class="n">conv_norm</span><span class="p">,</span>
            <span class="n">conv_act</span><span class="o">=</span><span class="n">conv_act</span><span class="p">,</span>
            <span class="n">interpolate_mode</span><span class="o">=</span><span class="n">interpolate_mode</span><span class="p">,</span>
            <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">aux_head1</span> <span class="o">=</span> <span class="n">_SETRUPHead</span><span class="p">(</span>
            <span class="n">channels</span><span class="o">=</span><span class="n">decoder_channels</span><span class="p">,</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span>
            <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
            <span class="n">num_convs</span><span class="o">=</span><span class="n">num_convs</span><span class="p">,</span>
            <span class="n">up_scale</span><span class="o">=</span><span class="n">up_scale</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">align_corners</span><span class="o">=</span><span class="n">align_corners</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">decoder_dropout</span><span class="p">,</span>
            <span class="n">conv_norm</span><span class="o">=</span><span class="n">conv_norm</span><span class="p">,</span>
            <span class="n">conv_act</span><span class="o">=</span><span class="n">conv_act</span><span class="p">,</span>
            <span class="n">interpolate_mode</span><span class="o">=</span><span class="n">interpolate_mode</span><span class="p">,</span>
            <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">aux_head2</span> <span class="o">=</span> <span class="n">_SETRUPHead</span><span class="p">(</span>
            <span class="n">channels</span><span class="o">=</span><span class="n">decoder_channels</span><span class="p">,</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span>
            <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
            <span class="n">num_convs</span><span class="o">=</span><span class="n">num_convs</span><span class="p">,</span>
            <span class="n">up_scale</span><span class="o">=</span><span class="n">up_scale</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">align_corners</span><span class="o">=</span><span class="n">align_corners</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">decoder_dropout</span><span class="p">,</span>
            <span class="n">conv_norm</span><span class="o">=</span><span class="n">conv_norm</span><span class="p">,</span>
            <span class="n">conv_act</span><span class="o">=</span><span class="n">conv_act</span><span class="p">,</span>
            <span class="n">interpolate_mode</span><span class="o">=</span><span class="n">interpolate_mode</span><span class="p">,</span>
            <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">aux_head3</span> <span class="o">=</span> <span class="n">_SETRUPHead</span><span class="p">(</span>
            <span class="n">channels</span><span class="o">=</span><span class="n">decoder_channels</span><span class="p">,</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span>
            <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
            <span class="n">num_convs</span><span class="o">=</span><span class="n">num_convs</span><span class="p">,</span>
            <span class="n">up_scale</span><span class="o">=</span><span class="n">up_scale</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">align_corners</span><span class="o">=</span><span class="n">align_corners</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">decoder_dropout</span><span class="p">,</span>
            <span class="n">conv_norm</span><span class="o">=</span><span class="n">conv_norm</span><span class="p">,</span>
            <span class="n">conv_act</span><span class="o">=</span><span class="n">conv_act</span><span class="p">,</span>
            <span class="n">interpolate_mode</span><span class="o">=</span><span class="n">interpolate_mode</span><span class="p">,</span>
            <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">,</span>
        <span class="p">)</span>

<div class="viewcode-block" id="_SetR_PUP.forward">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/image/setr/index.html#minerva.models.nets.image.setr._SetR_PUP.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux_output</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">aux_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x_aux1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux_head1</span><span class="p">(</span><span class="n">aux_results</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">x_aux2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux_head2</span><span class="p">(</span><span class="n">aux_results</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">x_aux3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux_head3</span><span class="p">(</span><span class="n">aux_results</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_aux1</span><span class="p">,</span> <span class="n">x_aux2</span><span class="p">,</span> <span class="n">x_aux3</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div>


<div class="viewcode-block" id="_SetR_PUP.load_backbone">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/image/setr/index.html#minerva.models.nets.image.setr._SetR_PUP.load_backbone">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_backbone</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">freeze</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">load_backbone</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">freeze</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span></div>
</div>



<div class="viewcode-block" id="SETR_PUP">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/index.html#minerva.models.nets.image.setr.SETR_PUP">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">SETR_PUP</span><span class="p">(</span><span class="n">L</span><span class="o">.</span><span class="n">LightningModule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;SET-R model with PUP head for image segmentation.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    forward(x: torch.Tensor) -&gt; torch.Tensor</span>
<span class="sd">        Forward pass of the model.</span>
<span class="sd">    _compute_metrics(y_hat: torch.Tensor, y: torch.Tensor, step_name: str)</span>
<span class="sd">        Compute metrics for the given step.</span>
<span class="sd">    _loss_func(y_hat: Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]], y: torch.Tensor) -&gt; torch.Tensor</span>
<span class="sd">        Calculate the loss between the output and the input data.</span>
<span class="sd">    _single_step(batch: torch.Tensor, batch_idx: int, step_name: str)</span>
<span class="sd">        Perform a single step of the training/validation loop.</span>
<span class="sd">    training_step(batch: torch.Tensor, batch_idx: int)</span>
<span class="sd">        Perform a single training step.</span>
<span class="sd">    validation_step(batch: torch.Tensor, batch_idx: int)</span>
<span class="sd">        Perform a single validation step.</span>
<span class="sd">    test_step(batch: torch.Tensor, batch_idx: int)</span>
<span class="sd">        Perform a single test step.</span>
<span class="sd">    predict_step(batch: torch.Tensor, batch_idx: int, dataloader_idx: Optional[int] = None)</span>
<span class="sd">        Perform a single prediction step.</span>
<span class="sd">    load_backbone(path: str, freeze: bool = False)</span>
<span class="sd">        Load a pre-trained backbone.</span>
<span class="sd">    configure_optimizers()</span>
<span class="sd">        Configure the optimizer for the model.</span>
<span class="sd">    create_from_dict(config: Dict) -&gt; &quot;SETR_PUP&quot;</span>
<span class="sd">        Create an instance of SETR_PUP from a configuration dictionary.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
        <span class="n">patch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
        <span class="n">num_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">24</span><span class="p">,</span>
        <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
        <span class="n">hidden_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
        <span class="n">mlp_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4096</span><span class="p">,</span>
        <span class="n">encoder_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">norm_layer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">decoder_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">256</span><span class="p">,</span>
        <span class="n">num_convs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">up_scale</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">align_corners</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">decoder_dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">conv_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">conv_act</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">interpolate_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;bilinear&quot;</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">optimizer_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">type</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">optimizer_params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">train_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Metric</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">val_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Metric</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">test_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Metric</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">aux_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">aux_output_layers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">aux_weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">load_backbone_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">freeze_backbone_on_load</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">loss_weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">original_resolution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">head_lr_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">test_engine</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_Engine</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the SETR model with Progressive Upsampling Head.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        image_size : Union[int, Tuple[int, int]], optional</span>
<span class="sd">            Size of the input image, by default 512.</span>
<span class="sd">        patch_size : int, optional</span>
<span class="sd">            Size of the patches to be extracted from the input image, by</span>
<span class="sd">            default 16.</span>
<span class="sd">        num_layers : int, optional</span>
<span class="sd">            Number of transformer layers, by default 24.</span>
<span class="sd">        num_heads : int, optional</span>
<span class="sd">            Number of attention heads, by default 16.</span>
<span class="sd">        hidden_dim : int, optional</span>
<span class="sd">            Dimension of the hidden layer, by default 1024.</span>
<span class="sd">        mlp_dim : int, optional</span>
<span class="sd">            Dimension of the MLP layer, by default 4096.</span>
<span class="sd">        encoder_dropout : float, optional</span>
<span class="sd">            Dropout rate for the encoder, by default 0.1.</span>
<span class="sd">        num_classes : int, optional</span>
<span class="sd">            Number of output classes, by default 1000.</span>
<span class="sd">        norm_layer : Optional[nn.Module], optional</span>
<span class="sd">            Normalization layer, by default None.</span>
<span class="sd">        decoder_channels : int, optional</span>
<span class="sd">            Number of channels in the decoder, by default 256.</span>
<span class="sd">        num_convs : int, optional</span>
<span class="sd">            Number of convolutional layers in the decoder, by default 4.</span>
<span class="sd">        up_scale : int, optional</span>
<span class="sd">            Upscaling factor for the decoder, by default 2.</span>
<span class="sd">        kernel_size : int, optional</span>
<span class="sd">            Kernel size for the convolutional layers, by default 3.</span>
<span class="sd">        align_corners : bool, optional</span>
<span class="sd">            Whether to align corners when interpolating, by default False.</span>
<span class="sd">        decoder_dropout : float, optional</span>
<span class="sd">            Dropout rate for the decoder, by default 0.1.</span>
<span class="sd">        conv_norm : Optional[nn.Module], optional</span>
<span class="sd">            Normalization layer for the convolutional layers, by default None.</span>
<span class="sd">        conv_act : Optional[nn.Module], optional</span>
<span class="sd">            Activation function for the convolutional layers, by default None.</span>
<span class="sd">        interpolate_mode : str, optional</span>
<span class="sd">            Interpolation mode, by default &quot;bilinear&quot;.</span>
<span class="sd">        loss_fn : Optional[nn.Module], optional</span>
<span class="sd">            Loss function, when None defaults to nn.CrossEntropyLoss, by</span>
<span class="sd">            default None.</span>
<span class="sd">        optimizer_type : Optional[type], optional</span>
<span class="sd">            Type of optimizer, by default None.</span>
<span class="sd">        optimizer_params : Optional[Dict], optional</span>
<span class="sd">            Parameters for the optimizer, by default None.</span>
<span class="sd">        train_metrics : Optional[Dict[str, Metric]], optional</span>
<span class="sd">            Metrics for training, by default None.</span>
<span class="sd">        val_metrics : Optional[Dict[str, Metric]], optional</span>
<span class="sd">            Metrics for validation, by default None.</span>
<span class="sd">        test_metrics : Optional[Dict[str, Metric]], optional</span>
<span class="sd">            Metrics for testing, by default None.</span>
<span class="sd">        aux_output : bool, optional</span>
<span class="sd">            Whether to use auxiliary outputs, by default True.</span>
<span class="sd">        aux_output_layers : list[int], optional</span>
<span class="sd">            Layers for auxiliary outputs, when None it defaults to [9, 14, 19].</span>
<span class="sd">        aux_weights : list[float], optional</span>
<span class="sd">            Weights for auxiliary outputs, when None it defaults [0.3, 0.3, 0.3].</span>
<span class="sd">        load_backbone_path : Optional[str], optional</span>
<span class="sd">            Path to load the backbone model, by default None.</span>
<span class="sd">        freeze_backbone_on_load : bool, optional</span>
<span class="sd">            Whether to freeze the backbone model on load, by default True.</span>
<span class="sd">        learning_rate : float, optional</span>
<span class="sd">            Learning rate, by default 1e-3.</span>
<span class="sd">        loss_weights : Optional[list[float]], optional</span>
<span class="sd">            Weights for the loss function, by default None.</span>
<span class="sd">        original_resolution : Optional[Tuple[int, int]], optional</span>
<span class="sd">            The original resolution of the input image in the pre-training</span>
<span class="sd">            weights. When None, positional embeddings will not be interpolated.</span>
<span class="sd">            Defaults to None.</span>
<span class="sd">        head_lr_factor : float, optional</span>
<span class="sd">            Learning rate factor for the head. used if you need different</span>
<span class="sd">            learning rates for backbone and prediction head, by default 1.0.</span>
<span class="sd">        test_engine : Optional[_Engine], optional</span>
<span class="sd">            Engine used for test and validation steps. When None, behavior of</span>
<span class="sd">            all steps, training, testing and validation is the same, by default None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">head_lr_factor</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">automatic_optimization</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">multiple_optimizers</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">automatic_optimization</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">multiple_optimizers</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">loss_fn</span>
            <span class="k">if</span> <span class="n">loss_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span>
                <span class="n">weight</span><span class="o">=</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">loss_weights</span><span class="p">)</span> <span class="k">if</span> <span class="n">loss_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">norm_layer</span> <span class="o">=</span> <span class="n">norm_layer</span> <span class="k">if</span> <span class="n">norm_layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">)</span>
        <span class="n">conv_norm</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">conv_norm</span> <span class="k">if</span> <span class="n">conv_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">SyncBatchNorm</span><span class="p">(</span><span class="n">decoder_channels</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">conv_act</span> <span class="o">=</span> <span class="n">conv_act</span> <span class="k">if</span> <span class="n">conv_act</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">aux_output</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">aux_output_layers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">aux_output_layers</span> <span class="o">=</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">19</span><span class="p">]</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;aux_output_layers not provided. Using default values [9, 14, 19].&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">aux_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">aux_weights</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;aux_weights not provided. Using default values [0.3, 0.3, 0.3].&quot;</span>
                <span class="p">)</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">aux_output_layers</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
            <span class="p">),</span> <span class="s2">&quot;aux_output_layers must have 3 values. Only 3 aux heads are supported.&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span> <span class="o">=</span> <span class="n">optimizer_type</span>
        <span class="k">if</span> <span class="n">optimizer_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">optimizer_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;optimizer_params must be provided.&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_params</span> <span class="o">=</span> <span class="n">optimizer_params</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aux_weights</span> <span class="o">=</span> <span class="n">aux_weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">head_lr_factor</span> <span class="o">=</span> <span class="n">head_lr_factor</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_metrics</span><span class="p">,</span>
            <span class="s2">&quot;val&quot;</span><span class="p">:</span> <span class="n">val_metrics</span><span class="p">,</span>
            <span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">test_metrics</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">_SetR_PUP</span><span class="p">(</span>
            <span class="n">image_size</span><span class="o">=</span><span class="n">image_size</span><span class="p">,</span>
            <span class="n">patch_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
            <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span>
            <span class="n">hidden_dim</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">,</span>
            <span class="n">mlp_dim</span><span class="o">=</span><span class="n">mlp_dim</span><span class="p">,</span>
            <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
            <span class="n">num_convs</span><span class="o">=</span><span class="n">num_convs</span><span class="p">,</span>
            <span class="n">up_scale</span><span class="o">=</span><span class="n">up_scale</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">conv_norm</span><span class="o">=</span><span class="n">conv_norm</span><span class="p">,</span>
            <span class="n">conv_act</span><span class="o">=</span><span class="n">conv_act</span><span class="p">,</span>
            <span class="n">decoder_channels</span><span class="o">=</span><span class="n">decoder_channels</span><span class="p">,</span>
            <span class="n">encoder_dropout</span><span class="o">=</span><span class="n">encoder_dropout</span><span class="p">,</span>
            <span class="n">decoder_dropout</span><span class="o">=</span><span class="n">decoder_dropout</span><span class="p">,</span>
            <span class="n">norm_layer</span><span class="o">=</span><span class="n">norm_layer</span><span class="p">,</span>
            <span class="n">interpolate_mode</span><span class="o">=</span><span class="n">interpolate_mode</span><span class="p">,</span>
            <span class="n">align_corners</span><span class="o">=</span><span class="n">align_corners</span><span class="p">,</span>
            <span class="n">aux_output</span><span class="o">=</span><span class="n">aux_output</span><span class="p">,</span>
            <span class="n">aux_output_layers</span><span class="o">=</span><span class="n">aux_output_layers</span><span class="p">,</span>
            <span class="n">original_resolution</span><span class="o">=</span><span class="n">original_resolution</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">load_backbone_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_backbone</span><span class="p">(</span><span class="n">load_backbone_path</span><span class="p">,</span> <span class="n">freeze_backbone_on_load</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_engine</span> <span class="o">=</span> <span class="n">test_engine</span>

<div class="viewcode-block" id="SETR_PUP.forward">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/index.html#minerva.models.nets.image.setr.SETR_PUP.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>


<div class="viewcode-block" id="SETR_PUP._compute_metrics">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/index.html#minerva.models.nets.image.setr.SETR_PUP._compute_metrics">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">step_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="n">step_name</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{}</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">step_name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">metric_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">metric</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">y</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">metric</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">[</span><span class="n">step_name</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span></div>


<div class="viewcode-block" id="SETR_PUP._loss_func">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/index.html#minerva.models.nets.image.setr.SETR_PUP._loss_func">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_loss_func</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">y_hat</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
            <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="p">],</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calculate the loss between the output and the input data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y_hat : torch.Tensor</span>
<span class="sd">            The output data from the forward pass.</span>
<span class="sd">        y : torch.Tensor</span>
<span class="sd">            The input data/label.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            The loss value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">y_hat</span><span class="p">,</span> <span class="n">y_aux1</span><span class="p">,</span> <span class="n">y_aux2</span><span class="p">,</span> <span class="n">y_aux3</span> <span class="o">=</span> <span class="n">y_hat</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
            <span class="n">loss_aux1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y_aux1</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
            <span class="n">loss_aux2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y_aux2</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
            <span class="n">loss_aux3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y_aux3</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="n">loss</span>
                <span class="o">+</span> <span class="p">(</span><span class="n">loss_aux1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux_weights</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="o">+</span> <span class="p">(</span><span class="n">loss_aux2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux_weights</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                <span class="o">+</span> <span class="p">(</span><span class="n">loss_aux3</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">aux_weights</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
            <span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">long</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="SETR_PUP._single_step">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/index.html#minerva.models.nets.image.setr.SETR_PUP._single_step">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">_single_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">step_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform a single step of the training/validation loop.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        batch : torch.Tensor</span>
<span class="sd">            The input data.</span>
<span class="sd">        batch_idx : int</span>
<span class="sd">            The index of the batch.</span>
<span class="sd">        step_name : str</span>
<span class="sd">            The name of the step, either &quot;train&quot; or &quot;val&quot;.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            The loss value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_engine</span> <span class="ow">and</span> <span class="p">(</span><span class="n">step_name</span> <span class="o">==</span> <span class="s2">&quot;test&quot;</span> <span class="ow">or</span> <span class="n">step_name</span> <span class="o">==</span> <span class="s2">&quot;val&quot;</span><span class="p">):</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_engine</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_metrics</span><span class="p">(</span><span class="n">y_hat</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="n">step_name</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_func</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_value</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
                <span class="n">metric_name</span><span class="p">,</span>
                <span class="n">metric_value</span><span class="p">,</span>
                <span class="n">on_step</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">logger</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">sync_dist</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">step_name</span><span class="si">}</span><span class="s2">_loss&quot;</span><span class="p">,</span>
            <span class="n">loss</span><span class="p">,</span>
            <span class="n">on_step</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">logger</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">sync_dist</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span></div>


<div class="viewcode-block" id="SETR_PUP.training_step">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/index.html#minerva.models.nets.image.setr.SETR_PUP.training_step">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiple_optimizers</span><span class="p">:</span>
            <span class="n">optimizers_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">()</span>

            <span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">optimizers_list</span><span class="p">:</span>
                <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_single_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">manual_backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">optimizers_list</span><span class="p">:</span>
                <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_single_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="s2">&quot;train&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="SETR_PUP.validation_step">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/index.html#minerva.models.nets.image.setr.SETR_PUP.validation_step">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_single_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="s2">&quot;val&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="SETR_PUP.test_step">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/index.html#minerva.models.nets.image.setr.SETR_PUP.test_step">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_single_step</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="SETR_PUP.predict_step">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/index.html#minerva.models.nets.image.setr.SETR_PUP.predict_step">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">batch</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">dataloader_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span></div>


<div class="viewcode-block" id="SETR_PUP.load_backbone">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/index.html#minerva.models.nets.image.setr.SETR_PUP.load_backbone">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_backbone</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">freeze</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_backbone</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">freeze</span><span class="p">)</span></div>


<div class="viewcode-block" id="SETR_PUP.configure_optimizers">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/index.html#minerva.models.nets.image.setr.SETR_PUP.configure_optimizers">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiple_optimizers</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="p">[</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                        <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
                        <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_params</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span><span class="p">(</span>
                        <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
                        <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">aux_head1</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
                        <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">aux_head2</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
                        <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">aux_head3</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span>
                        <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">head_lr_factor</span><span class="p">,</span>
                        <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_params</span><span class="p">,</span>
                    <span class="p">),</span>
                <span class="p">]</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="k">else</span> <span class="p">[</span>
                    <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">),</span>
                    <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">),</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                    <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">,</span>
                    <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_params</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="k">else</span> <span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
            <span class="p">)</span></div>


<div class="viewcode-block" id="SETR_PUP.create_from_dict">
<a class="viewcode-back" href="../../../../../autoapi/minerva/models/nets/index.html#minerva.models.nets.image.setr.SETR_PUP.create_from_dict">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_from_dict</span><span class="p">(</span><span class="n">config</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SETR_PUP&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">SETR_PUP</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Unicamp.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>