minerva.models.ssl.simclr
=========================

.. py:module:: minerva.models.ssl.simclr


Classes
-------

.. autoapisummary::

   minerva.models.ssl.simclr.SimCLR


Module Contents
---------------

.. py:class:: SimCLR(backbone, projection_head, flatten = True, temperature = 0.5, lr = 0.001)

   Bases: :py:obj:`lightning.LightningModule`


   Base class for all neural network modules.

   Your models should also subclass this class.

   Modules can also contain other Modules, allowing them to be nested in
   a tree structure. You can assign the submodules as regular attributes::

       import torch.nn as nn
       import torch.nn.functional as F

       class Model(nn.Module):
           def __init__(self) -> None:
               super().__init__()
               self.conv1 = nn.Conv2d(1, 20, 5)
               self.conv2 = nn.Conv2d(20, 20, 5)

           def forward(self, x):
               x = F.relu(self.conv1(x))
               return F.relu(self.conv2(x))

   Submodules assigned in this way will be registered, and will also have their
   parameters converted when you call :meth:`to`, etc.

   .. note::
       As per the example above, an ``__init__()`` call to the parent class
       must be made before assignment on the child.

   :ivar training: Boolean represents whether this module is in training or
                   evaluation mode.
   :vartype training: bool

   Initializes the SimCLR model.

   Parameters
   ----------
   backbone : nn.Module
       Backbone model for feature extraction.
   projection_head : nn.Module
       Projection head model.
   flatten : bool, optional, default=True
       Whether to flatten the output of the backbone model, by default True
   temperature : float, optional, default=0.5
       Temperature for the NT-Xent loss, by default 0.5
   lr : float, optional, default=1e-3
       Learning rate for the optimizer, by default 1e-3


   .. py:method:: _single_step(batch)

      Performs a single forward and loss computation step.

      Parameters
      ----------
      batch : Tuple[Tuple[Tensor, Tensor], Any]
          Input batch containing images and optional labels.

      Returns
      -------
      Tensor
          Computed loss for the batch.



   .. py:attribute:: backbone


   .. py:method:: configure_optimizers()

      Configures the optimizer for training.

      Returns
      -------
      torch.optim.Optimizer
          Optimizer instance.



   .. py:attribute:: flatten
      :value: True



   .. py:method:: forward(x)

      Forward pass through the SimCLR model.

      Parameters
      ----------
      x : Tuple[Tensor, Tensor]
          Input tensor of features with shape (batch_size, input_dim).

      Returns
      -------
      Tensor
          Output tensor of projected features with shape (batch_size, output_dim).



   .. py:attribute:: loss


   .. py:attribute:: lr
      :value: 0.001



   .. py:method:: predict_step(batch, batch_idx, dataloader_idx = None)

      Predict step.

      Parameters
      ----------
      batch : Tuple[Tuple[Tensor, Tensor], Any]
          Input batch containing images and optional labels.
      batch_idx : int
          Index of the current batch.
      dataloader_idx : Optional[int], optional
          Index of the dataloader, by default None

      Returns
      -------
      Tensor
          Computed loss for the batch.



   .. py:attribute:: projector


   .. py:method:: training_step(batch, batch_idx)

      Training step.

      Parameters
      ----------
      batch : Tuple[Tuple[Tensor, Tensor], Any]
          Input batch containing images and optional labels.
      batch_idx : int
          Index of the current batch.

      Returns
      -------
      Tensor
          Computed loss for the batch.



   .. py:method:: validation_step(batch, batch_idx)

      Validation step.

      Parameters
      ----------
      batch : Tuple[Tuple[Tensor, Tensor], Any]
          Input batch containing images and optional labels.
      batch_idx : int
          Index of the current batch.

      Returns
      -------
      Tensor
          Computed loss for the batch.



