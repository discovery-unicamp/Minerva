{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training with Learning from Randomness (LFR) on the Parihaka dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from minerva.models.ssl import LearnFromRandomnessModel, RepeatedModuleList\n",
    "from minerva.models.nets.image.deeplabv3 import DeepLabV3Backbone\n",
    "from minerva.pipelines.lightning_pipeline import SimpleLightningPipeline\n",
    "from minerva.data.data_modules.seismic_image import SeismicImageDataModule\n",
    "from functools import partial\n",
    "from common import get_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "dataset_name = \"seam_ai\"        # Dataset name (just identifier)\n",
    "data_dir = \"/shared/datasets/seam_ai\"\n",
    "batch_size = 1\n",
    "image_size = (1024, 1024)\n",
    "\n",
    "# Model\n",
    "model_name = \"lfr_5\"            # Model name (just identifier)\n",
    "n_prediction_heads = 5\n",
    "\n",
    "# Training\n",
    "learning_rate = 1e-4\n",
    "log_dir = \"./logs\"              # Directory to save logs\n",
    "batch_size = 1                  # Batch size    \n",
    "seed = 42                       # Seed for reproducibility\n",
    "num_epochs = 100                # Number of epochs to train\n",
    "is_debug = True                 # If True, only 3 batch will be processed for 3 epochs\n",
    "accelerator = \"gpu\"             # CPU or GPU\n",
    "devices = 1                     # Num GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = SeismicImageDataModule(\n",
    "    root_dirs=data_dir,\n",
    "    batch_size=batch_size,\n",
    "    resize=image_size,\n",
    "    labels=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Projector = partial(\n",
    "    nn.Sequential,\n",
    "    nn.Conv2d(3, 32, 3, 2, 1),\n",
    "    nn.ReLU(True),\n",
    "    nn.Conv2d(32, 256, 3, 2, 1),\n",
    "    nn.ReLU(True),\n",
    "    nn.Conv2d(256, 2048, 3, 2, 1),\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(2048, 256, 3, 2, 1, 1),\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(256, 32, 3, 2, 1, 1),\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(32, 1, 3, 2, 1, 1)\n",
    ")\n",
    "\n",
    "Predictor = partial(\n",
    "    nn.Sequential,\n",
    "    nn.ConvTranspose2d(2048, 256, 3, 2, 1, 1),\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(256, 32, 3, 2, 1, 1),\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose2d(32, 1, 3, 2, 1, 1)\n",
    ")\n",
    "\n",
    "\n",
    "LFR_model = LearnFromRandomnessModel(\n",
    "    backbone=DeepLabV3Backbone(),\n",
    "    projectors=RepeatedModuleList(n_prediction_heads, Projector),\n",
    "    predictors=RepeatedModuleList(n_prediction_heads, Predictor),\n",
    "    loss_fn=nn.MSELoss(),\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "LFR_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = get_trainer(\n",
    "    model_name,\n",
    "    dataset_name,\n",
    "    log_dir,\n",
    "    num_epochs,\n",
    "    accelerator,\n",
    "    devices,\n",
    "    is_debug,\n",
    ")\n",
    "\n",
    "pipeline = SimpleLightningPipeline(LFR_model, trainer, log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.run(data_module, task=\"fit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
