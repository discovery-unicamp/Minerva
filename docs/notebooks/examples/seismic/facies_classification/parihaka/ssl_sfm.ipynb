{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:54: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from common import *\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "import lightning as L\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import JaccardIndex\n",
    "\n",
    "from minerva.data.datasets.supervised_dataset import SupervisedReconstructionDataset\n",
    "from minerva.data.readers.png_reader import PNGReader\n",
    "from minerva.data.readers.tiff_reader import TiffReader\n",
    "from minerva.models.loaders import FromPretrained\n",
    "from minerva.models.nets.image.vit import SFM_BasePatch16_Downstream\n",
    "from minerva.pipelines.lightning_pipeline import SimpleLightningPipeline\n",
    "from minerva.transforms.transform import _Transform, TransformPipeline\n",
    "from lightning.pytorch.loggers.csv_logs import CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataModule\n",
       "    Data: /workspaces/HIAAC-KR-Dev-Container/shared_data/seam_ai_datasets/seam_ai/images\n",
       "    Annotations: /workspaces/HIAAC-KR-Dev-Container/shared_data/seam_ai_datasets/seam_ai/annotations\n",
       "    Batch size: 1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_data_dir = \"/workspaces/HIAAC-KR-Dev-Container/shared_data/seam_ai_datasets/seam_ai/images\"\n",
    "root_annotation_dir = \"/workspaces/HIAAC-KR-Dev-Container/shared_data/seam_ai_datasets/seam_ai/annotations\"\n",
    "\n",
    "\n",
    "data_module = GenericDataModule(\n",
    "    root_data_dir=root_data_dir,\n",
    "    root_annotation_dir=root_annotation_dir,\n",
    "    transforms=[\n",
    "        TransformPipeline([\n",
    "            SelectChannel(0),\n",
    "            PadCrop(512, 512, padding_mode=\"reflect\", seed=42, constant_values=0),\n",
    "            CastTo(np.float32),\n",
    "        ]), \n",
    "\n",
    "        TransformPipeline([\n",
    "            PadCrop(512, 512, padding_mode=\"reflect\", seed=42, constant_values=0),\n",
    "            CastTo(np.int64),\n",
    "        ]), \n",
    "    ],\n",
    "    batch_size=1,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512, 512]) torch.Size([1, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "data_module.setup(\"fit\")\n",
    "batch = next(iter(data_module.train_dataloader()))\n",
    "print(batch[0].shape, batch[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SFM_BasePatch16_Downstream(\n",
       "  (backbone): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Linear(in_features=768, out_features=6, bias=True)\n",
       "    (decoder): VIT_MLAHead(\n",
       "      (mlahead): MLAHead(\n",
       "        (head2): Sequential(\n",
       "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "        (head3): Sequential(\n",
       "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "        (head4): Sequential(\n",
       "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "        (head5): Sequential(\n",
       "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (cls): Conv2d(512, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (segmentation_head): SegmentationHead(\n",
       "      (0): Conv2d(16, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Identity()\n",
       "    )\n",
       "    (loss_fn): CrossEntropyLoss()\n",
       "  )\n",
       "  (fc): Identity()\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SFM_BasePatch16_Downstream(\n",
    "    img_size=(512, 512),\n",
    "    num_classes=6,\n",
    "    in_chans=1\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing key renaming with: {'': 'backbone.model.'}\n",
      "\tRenaming key: cls_token -> backbone.model.cls_token (changed: True)\n",
      "\tRenaming key: pos_embed -> backbone.model.pos_embed (changed: True)\n",
      "\tRenaming key: patch_embed.proj.weight -> backbone.model.patch_embed.proj.weight (changed: True)\n",
      "\tRenaming key: patch_embed.proj.bias -> backbone.model.patch_embed.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.0.norm1.weight -> backbone.model.blocks.0.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.0.norm1.bias -> backbone.model.blocks.0.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.0.attn.qkv.weight -> backbone.model.blocks.0.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.0.attn.qkv.bias -> backbone.model.blocks.0.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.0.attn.proj.weight -> backbone.model.blocks.0.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.0.attn.proj.bias -> backbone.model.blocks.0.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.0.norm2.weight -> backbone.model.blocks.0.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.0.norm2.bias -> backbone.model.blocks.0.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.0.mlp.fc1.weight -> backbone.model.blocks.0.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.0.mlp.fc1.bias -> backbone.model.blocks.0.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.0.mlp.fc2.weight -> backbone.model.blocks.0.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.0.mlp.fc2.bias -> backbone.model.blocks.0.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.1.norm1.weight -> backbone.model.blocks.1.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.1.norm1.bias -> backbone.model.blocks.1.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.1.attn.qkv.weight -> backbone.model.blocks.1.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.1.attn.qkv.bias -> backbone.model.blocks.1.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.1.attn.proj.weight -> backbone.model.blocks.1.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.1.attn.proj.bias -> backbone.model.blocks.1.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.1.norm2.weight -> backbone.model.blocks.1.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.1.norm2.bias -> backbone.model.blocks.1.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.1.mlp.fc1.weight -> backbone.model.blocks.1.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.1.mlp.fc1.bias -> backbone.model.blocks.1.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.1.mlp.fc2.weight -> backbone.model.blocks.1.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.1.mlp.fc2.bias -> backbone.model.blocks.1.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.2.norm1.weight -> backbone.model.blocks.2.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.2.norm1.bias -> backbone.model.blocks.2.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.2.attn.qkv.weight -> backbone.model.blocks.2.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.2.attn.qkv.bias -> backbone.model.blocks.2.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.2.attn.proj.weight -> backbone.model.blocks.2.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.2.attn.proj.bias -> backbone.model.blocks.2.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.2.norm2.weight -> backbone.model.blocks.2.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.2.norm2.bias -> backbone.model.blocks.2.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.2.mlp.fc1.weight -> backbone.model.blocks.2.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.2.mlp.fc1.bias -> backbone.model.blocks.2.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.2.mlp.fc2.weight -> backbone.model.blocks.2.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.2.mlp.fc2.bias -> backbone.model.blocks.2.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.3.norm1.weight -> backbone.model.blocks.3.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.3.norm1.bias -> backbone.model.blocks.3.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.3.attn.qkv.weight -> backbone.model.blocks.3.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.3.attn.qkv.bias -> backbone.model.blocks.3.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.3.attn.proj.weight -> backbone.model.blocks.3.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.3.attn.proj.bias -> backbone.model.blocks.3.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.3.norm2.weight -> backbone.model.blocks.3.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.3.norm2.bias -> backbone.model.blocks.3.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.3.mlp.fc1.weight -> backbone.model.blocks.3.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.3.mlp.fc1.bias -> backbone.model.blocks.3.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.3.mlp.fc2.weight -> backbone.model.blocks.3.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.3.mlp.fc2.bias -> backbone.model.blocks.3.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.4.norm1.weight -> backbone.model.blocks.4.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.4.norm1.bias -> backbone.model.blocks.4.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.4.attn.qkv.weight -> backbone.model.blocks.4.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.4.attn.qkv.bias -> backbone.model.blocks.4.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.4.attn.proj.weight -> backbone.model.blocks.4.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.4.attn.proj.bias -> backbone.model.blocks.4.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.4.norm2.weight -> backbone.model.blocks.4.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.4.norm2.bias -> backbone.model.blocks.4.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.4.mlp.fc1.weight -> backbone.model.blocks.4.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.4.mlp.fc1.bias -> backbone.model.blocks.4.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.4.mlp.fc2.weight -> backbone.model.blocks.4.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.4.mlp.fc2.bias -> backbone.model.blocks.4.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.5.norm1.weight -> backbone.model.blocks.5.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.5.norm1.bias -> backbone.model.blocks.5.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.5.attn.qkv.weight -> backbone.model.blocks.5.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.5.attn.qkv.bias -> backbone.model.blocks.5.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.5.attn.proj.weight -> backbone.model.blocks.5.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.5.attn.proj.bias -> backbone.model.blocks.5.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.5.norm2.weight -> backbone.model.blocks.5.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.5.norm2.bias -> backbone.model.blocks.5.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.5.mlp.fc1.weight -> backbone.model.blocks.5.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.5.mlp.fc1.bias -> backbone.model.blocks.5.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.5.mlp.fc2.weight -> backbone.model.blocks.5.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.5.mlp.fc2.bias -> backbone.model.blocks.5.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.6.norm1.weight -> backbone.model.blocks.6.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.6.norm1.bias -> backbone.model.blocks.6.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.6.attn.qkv.weight -> backbone.model.blocks.6.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.6.attn.qkv.bias -> backbone.model.blocks.6.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.6.attn.proj.weight -> backbone.model.blocks.6.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.6.attn.proj.bias -> backbone.model.blocks.6.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.6.norm2.weight -> backbone.model.blocks.6.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.6.norm2.bias -> backbone.model.blocks.6.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.6.mlp.fc1.weight -> backbone.model.blocks.6.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.6.mlp.fc1.bias -> backbone.model.blocks.6.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.6.mlp.fc2.weight -> backbone.model.blocks.6.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.6.mlp.fc2.bias -> backbone.model.blocks.6.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.7.norm1.weight -> backbone.model.blocks.7.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.7.norm1.bias -> backbone.model.blocks.7.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.7.attn.qkv.weight -> backbone.model.blocks.7.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.7.attn.qkv.bias -> backbone.model.blocks.7.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.7.attn.proj.weight -> backbone.model.blocks.7.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.7.attn.proj.bias -> backbone.model.blocks.7.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.7.norm2.weight -> backbone.model.blocks.7.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.7.norm2.bias -> backbone.model.blocks.7.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.7.mlp.fc1.weight -> backbone.model.blocks.7.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.7.mlp.fc1.bias -> backbone.model.blocks.7.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.7.mlp.fc2.weight -> backbone.model.blocks.7.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.7.mlp.fc2.bias -> backbone.model.blocks.7.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.8.norm1.weight -> backbone.model.blocks.8.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.8.norm1.bias -> backbone.model.blocks.8.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.8.attn.qkv.weight -> backbone.model.blocks.8.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.8.attn.qkv.bias -> backbone.model.blocks.8.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.8.attn.proj.weight -> backbone.model.blocks.8.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.8.attn.proj.bias -> backbone.model.blocks.8.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.8.norm2.weight -> backbone.model.blocks.8.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.8.norm2.bias -> backbone.model.blocks.8.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.8.mlp.fc1.weight -> backbone.model.blocks.8.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.8.mlp.fc1.bias -> backbone.model.blocks.8.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.8.mlp.fc2.weight -> backbone.model.blocks.8.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.8.mlp.fc2.bias -> backbone.model.blocks.8.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.9.norm1.weight -> backbone.model.blocks.9.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.9.norm1.bias -> backbone.model.blocks.9.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.9.attn.qkv.weight -> backbone.model.blocks.9.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.9.attn.qkv.bias -> backbone.model.blocks.9.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.9.attn.proj.weight -> backbone.model.blocks.9.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.9.attn.proj.bias -> backbone.model.blocks.9.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.9.norm2.weight -> backbone.model.blocks.9.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.9.norm2.bias -> backbone.model.blocks.9.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.9.mlp.fc1.weight -> backbone.model.blocks.9.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.9.mlp.fc1.bias -> backbone.model.blocks.9.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.9.mlp.fc2.weight -> backbone.model.blocks.9.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.9.mlp.fc2.bias -> backbone.model.blocks.9.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.10.norm1.weight -> backbone.model.blocks.10.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.10.norm1.bias -> backbone.model.blocks.10.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.10.attn.qkv.weight -> backbone.model.blocks.10.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.10.attn.qkv.bias -> backbone.model.blocks.10.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.10.attn.proj.weight -> backbone.model.blocks.10.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.10.attn.proj.bias -> backbone.model.blocks.10.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.10.norm2.weight -> backbone.model.blocks.10.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.10.norm2.bias -> backbone.model.blocks.10.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.10.mlp.fc1.weight -> backbone.model.blocks.10.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.10.mlp.fc1.bias -> backbone.model.blocks.10.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.10.mlp.fc2.weight -> backbone.model.blocks.10.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.10.mlp.fc2.bias -> backbone.model.blocks.10.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.11.norm1.weight -> backbone.model.blocks.11.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.11.norm1.bias -> backbone.model.blocks.11.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.11.attn.qkv.weight -> backbone.model.blocks.11.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.11.attn.qkv.bias -> backbone.model.blocks.11.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.11.attn.proj.weight -> backbone.model.blocks.11.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.11.attn.proj.bias -> backbone.model.blocks.11.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.11.norm2.weight -> backbone.model.blocks.11.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.11.norm2.bias -> backbone.model.blocks.11.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.11.mlp.fc1.weight -> backbone.model.blocks.11.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.11.mlp.fc1.bias -> backbone.model.blocks.11.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.11.mlp.fc2.weight -> backbone.model.blocks.11.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.11.mlp.fc2.bias -> backbone.model.blocks.11.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: norm.weight -> backbone.model.norm.weight (changed: True)\n",
      "\tRenaming key: norm.bias -> backbone.model.norm.bias (changed: True)\n",
      "Model loaded from /workspaces/HIAAC-KR-Dev-Container/shared_data/seismic_foundation_model/pretrained_models/SFM-Base-512.pth\n",
      "When loading model, the following keys are missing: ['backbone.cls_token', 'backbone.pos_embed', 'backbone.patch_embed.proj.weight', 'backbone.patch_embed.proj.bias', 'backbone.blocks.0.norm1.weight', 'backbone.blocks.0.norm1.bias', 'backbone.blocks.0.attn.qkv.weight', 'backbone.blocks.0.attn.qkv.bias', 'backbone.blocks.0.attn.proj.weight', 'backbone.blocks.0.attn.proj.bias', 'backbone.blocks.0.norm2.weight', 'backbone.blocks.0.norm2.bias', 'backbone.blocks.0.mlp.fc1.weight', 'backbone.blocks.0.mlp.fc1.bias', 'backbone.blocks.0.mlp.fc2.weight', 'backbone.blocks.0.mlp.fc2.bias', 'backbone.blocks.1.norm1.weight', 'backbone.blocks.1.norm1.bias', 'backbone.blocks.1.attn.qkv.weight', 'backbone.blocks.1.attn.qkv.bias', 'backbone.blocks.1.attn.proj.weight', 'backbone.blocks.1.attn.proj.bias', 'backbone.blocks.1.norm2.weight', 'backbone.blocks.1.norm2.bias', 'backbone.blocks.1.mlp.fc1.weight', 'backbone.blocks.1.mlp.fc1.bias', 'backbone.blocks.1.mlp.fc2.weight', 'backbone.blocks.1.mlp.fc2.bias', 'backbone.blocks.2.norm1.weight', 'backbone.blocks.2.norm1.bias', 'backbone.blocks.2.attn.qkv.weight', 'backbone.blocks.2.attn.qkv.bias', 'backbone.blocks.2.attn.proj.weight', 'backbone.blocks.2.attn.proj.bias', 'backbone.blocks.2.norm2.weight', 'backbone.blocks.2.norm2.bias', 'backbone.blocks.2.mlp.fc1.weight', 'backbone.blocks.2.mlp.fc1.bias', 'backbone.blocks.2.mlp.fc2.weight', 'backbone.blocks.2.mlp.fc2.bias', 'backbone.blocks.3.norm1.weight', 'backbone.blocks.3.norm1.bias', 'backbone.blocks.3.attn.qkv.weight', 'backbone.blocks.3.attn.qkv.bias', 'backbone.blocks.3.attn.proj.weight', 'backbone.blocks.3.attn.proj.bias', 'backbone.blocks.3.norm2.weight', 'backbone.blocks.3.norm2.bias', 'backbone.blocks.3.mlp.fc1.weight', 'backbone.blocks.3.mlp.fc1.bias', 'backbone.blocks.3.mlp.fc2.weight', 'backbone.blocks.3.mlp.fc2.bias', 'backbone.blocks.4.norm1.weight', 'backbone.blocks.4.norm1.bias', 'backbone.blocks.4.attn.qkv.weight', 'backbone.blocks.4.attn.qkv.bias', 'backbone.blocks.4.attn.proj.weight', 'backbone.blocks.4.attn.proj.bias', 'backbone.blocks.4.norm2.weight', 'backbone.blocks.4.norm2.bias', 'backbone.blocks.4.mlp.fc1.weight', 'backbone.blocks.4.mlp.fc1.bias', 'backbone.blocks.4.mlp.fc2.weight', 'backbone.blocks.4.mlp.fc2.bias', 'backbone.blocks.5.norm1.weight', 'backbone.blocks.5.norm1.bias', 'backbone.blocks.5.attn.qkv.weight', 'backbone.blocks.5.attn.qkv.bias', 'backbone.blocks.5.attn.proj.weight', 'backbone.blocks.5.attn.proj.bias', 'backbone.blocks.5.norm2.weight', 'backbone.blocks.5.norm2.bias', 'backbone.blocks.5.mlp.fc1.weight', 'backbone.blocks.5.mlp.fc1.bias', 'backbone.blocks.5.mlp.fc2.weight', 'backbone.blocks.5.mlp.fc2.bias', 'backbone.blocks.6.norm1.weight', 'backbone.blocks.6.norm1.bias', 'backbone.blocks.6.attn.qkv.weight', 'backbone.blocks.6.attn.qkv.bias', 'backbone.blocks.6.attn.proj.weight', 'backbone.blocks.6.attn.proj.bias', 'backbone.blocks.6.norm2.weight', 'backbone.blocks.6.norm2.bias', 'backbone.blocks.6.mlp.fc1.weight', 'backbone.blocks.6.mlp.fc1.bias', 'backbone.blocks.6.mlp.fc2.weight', 'backbone.blocks.6.mlp.fc2.bias', 'backbone.blocks.7.norm1.weight', 'backbone.blocks.7.norm1.bias', 'backbone.blocks.7.attn.qkv.weight', 'backbone.blocks.7.attn.qkv.bias', 'backbone.blocks.7.attn.proj.weight', 'backbone.blocks.7.attn.proj.bias', 'backbone.blocks.7.norm2.weight', 'backbone.blocks.7.norm2.bias', 'backbone.blocks.7.mlp.fc1.weight', 'backbone.blocks.7.mlp.fc1.bias', 'backbone.blocks.7.mlp.fc2.weight', 'backbone.blocks.7.mlp.fc2.bias', 'backbone.blocks.8.norm1.weight', 'backbone.blocks.8.norm1.bias', 'backbone.blocks.8.attn.qkv.weight', 'backbone.blocks.8.attn.qkv.bias', 'backbone.blocks.8.attn.proj.weight', 'backbone.blocks.8.attn.proj.bias', 'backbone.blocks.8.norm2.weight', 'backbone.blocks.8.norm2.bias', 'backbone.blocks.8.mlp.fc1.weight', 'backbone.blocks.8.mlp.fc1.bias', 'backbone.blocks.8.mlp.fc2.weight', 'backbone.blocks.8.mlp.fc2.bias', 'backbone.blocks.9.norm1.weight', 'backbone.blocks.9.norm1.bias', 'backbone.blocks.9.attn.qkv.weight', 'backbone.blocks.9.attn.qkv.bias', 'backbone.blocks.9.attn.proj.weight', 'backbone.blocks.9.attn.proj.bias', 'backbone.blocks.9.norm2.weight', 'backbone.blocks.9.norm2.bias', 'backbone.blocks.9.mlp.fc1.weight', 'backbone.blocks.9.mlp.fc1.bias', 'backbone.blocks.9.mlp.fc2.weight', 'backbone.blocks.9.mlp.fc2.bias', 'backbone.blocks.10.norm1.weight', 'backbone.blocks.10.norm1.bias', 'backbone.blocks.10.attn.qkv.weight', 'backbone.blocks.10.attn.qkv.bias', 'backbone.blocks.10.attn.proj.weight', 'backbone.blocks.10.attn.proj.bias', 'backbone.blocks.10.norm2.weight', 'backbone.blocks.10.norm2.bias', 'backbone.blocks.10.mlp.fc1.weight', 'backbone.blocks.10.mlp.fc1.bias', 'backbone.blocks.10.mlp.fc2.weight', 'backbone.blocks.10.mlp.fc2.bias', 'backbone.blocks.11.norm1.weight', 'backbone.blocks.11.norm1.bias', 'backbone.blocks.11.attn.qkv.weight', 'backbone.blocks.11.attn.qkv.bias', 'backbone.blocks.11.attn.proj.weight', 'backbone.blocks.11.attn.proj.bias', 'backbone.blocks.11.norm2.weight', 'backbone.blocks.11.norm2.bias', 'backbone.blocks.11.mlp.fc1.weight', 'backbone.blocks.11.mlp.fc1.bias', 'backbone.blocks.11.mlp.fc2.weight', 'backbone.blocks.11.mlp.fc2.bias', 'backbone.norm.weight', 'backbone.norm.bias', 'backbone.head.weight', 'backbone.head.bias', 'backbone.decoder.mlahead.head2.0.weight', 'backbone.decoder.mlahead.head2.1.weight', 'backbone.decoder.mlahead.head2.1.bias', 'backbone.decoder.mlahead.head2.1.running_mean', 'backbone.decoder.mlahead.head2.1.running_var', 'backbone.decoder.mlahead.head2.3.weight', 'backbone.decoder.mlahead.head2.4.weight', 'backbone.decoder.mlahead.head2.4.bias', 'backbone.decoder.mlahead.head2.4.running_mean', 'backbone.decoder.mlahead.head2.4.running_var', 'backbone.decoder.mlahead.head3.0.weight', 'backbone.decoder.mlahead.head3.1.weight', 'backbone.decoder.mlahead.head3.1.bias', 'backbone.decoder.mlahead.head3.1.running_mean', 'backbone.decoder.mlahead.head3.1.running_var', 'backbone.decoder.mlahead.head3.3.weight', 'backbone.decoder.mlahead.head3.4.weight', 'backbone.decoder.mlahead.head3.4.bias', 'backbone.decoder.mlahead.head3.4.running_mean', 'backbone.decoder.mlahead.head3.4.running_var', 'backbone.decoder.mlahead.head4.0.weight', 'backbone.decoder.mlahead.head4.1.weight', 'backbone.decoder.mlahead.head4.1.bias', 'backbone.decoder.mlahead.head4.1.running_mean', 'backbone.decoder.mlahead.head4.1.running_var', 'backbone.decoder.mlahead.head4.3.weight', 'backbone.decoder.mlahead.head4.4.weight', 'backbone.decoder.mlahead.head4.4.bias', 'backbone.decoder.mlahead.head4.4.running_mean', 'backbone.decoder.mlahead.head4.4.running_var', 'backbone.decoder.mlahead.head5.0.weight', 'backbone.decoder.mlahead.head5.1.weight', 'backbone.decoder.mlahead.head5.1.bias', 'backbone.decoder.mlahead.head5.1.running_mean', 'backbone.decoder.mlahead.head5.1.running_var', 'backbone.decoder.mlahead.head5.3.weight', 'backbone.decoder.mlahead.head5.4.weight', 'backbone.decoder.mlahead.head5.4.bias', 'backbone.decoder.mlahead.head5.4.running_mean', 'backbone.decoder.mlahead.head5.4.running_var', 'backbone.decoder.cls.weight', 'backbone.decoder.cls.bias', 'backbone.segmentation_head.0.weight', 'backbone.segmentation_head.0.bias']\n",
      "When loading model, the following keys are unexpected: ['backbone.model.cls_token', 'backbone.model.pos_embed', 'backbone.model.patch_embed.proj.weight', 'backbone.model.patch_embed.proj.bias', 'backbone.model.blocks.0.norm1.weight', 'backbone.model.blocks.0.norm1.bias', 'backbone.model.blocks.0.attn.qkv.weight', 'backbone.model.blocks.0.attn.qkv.bias', 'backbone.model.blocks.0.attn.proj.weight', 'backbone.model.blocks.0.attn.proj.bias', 'backbone.model.blocks.0.norm2.weight', 'backbone.model.blocks.0.norm2.bias', 'backbone.model.blocks.0.mlp.fc1.weight', 'backbone.model.blocks.0.mlp.fc1.bias', 'backbone.model.blocks.0.mlp.fc2.weight', 'backbone.model.blocks.0.mlp.fc2.bias', 'backbone.model.blocks.1.norm1.weight', 'backbone.model.blocks.1.norm1.bias', 'backbone.model.blocks.1.attn.qkv.weight', 'backbone.model.blocks.1.attn.qkv.bias', 'backbone.model.blocks.1.attn.proj.weight', 'backbone.model.blocks.1.attn.proj.bias', 'backbone.model.blocks.1.norm2.weight', 'backbone.model.blocks.1.norm2.bias', 'backbone.model.blocks.1.mlp.fc1.weight', 'backbone.model.blocks.1.mlp.fc1.bias', 'backbone.model.blocks.1.mlp.fc2.weight', 'backbone.model.blocks.1.mlp.fc2.bias', 'backbone.model.blocks.2.norm1.weight', 'backbone.model.blocks.2.norm1.bias', 'backbone.model.blocks.2.attn.qkv.weight', 'backbone.model.blocks.2.attn.qkv.bias', 'backbone.model.blocks.2.attn.proj.weight', 'backbone.model.blocks.2.attn.proj.bias', 'backbone.model.blocks.2.norm2.weight', 'backbone.model.blocks.2.norm2.bias', 'backbone.model.blocks.2.mlp.fc1.weight', 'backbone.model.blocks.2.mlp.fc1.bias', 'backbone.model.blocks.2.mlp.fc2.weight', 'backbone.model.blocks.2.mlp.fc2.bias', 'backbone.model.blocks.3.norm1.weight', 'backbone.model.blocks.3.norm1.bias', 'backbone.model.blocks.3.attn.qkv.weight', 'backbone.model.blocks.3.attn.qkv.bias', 'backbone.model.blocks.3.attn.proj.weight', 'backbone.model.blocks.3.attn.proj.bias', 'backbone.model.blocks.3.norm2.weight', 'backbone.model.blocks.3.norm2.bias', 'backbone.model.blocks.3.mlp.fc1.weight', 'backbone.model.blocks.3.mlp.fc1.bias', 'backbone.model.blocks.3.mlp.fc2.weight', 'backbone.model.blocks.3.mlp.fc2.bias', 'backbone.model.blocks.4.norm1.weight', 'backbone.model.blocks.4.norm1.bias', 'backbone.model.blocks.4.attn.qkv.weight', 'backbone.model.blocks.4.attn.qkv.bias', 'backbone.model.blocks.4.attn.proj.weight', 'backbone.model.blocks.4.attn.proj.bias', 'backbone.model.blocks.4.norm2.weight', 'backbone.model.blocks.4.norm2.bias', 'backbone.model.blocks.4.mlp.fc1.weight', 'backbone.model.blocks.4.mlp.fc1.bias', 'backbone.model.blocks.4.mlp.fc2.weight', 'backbone.model.blocks.4.mlp.fc2.bias', 'backbone.model.blocks.5.norm1.weight', 'backbone.model.blocks.5.norm1.bias', 'backbone.model.blocks.5.attn.qkv.weight', 'backbone.model.blocks.5.attn.qkv.bias', 'backbone.model.blocks.5.attn.proj.weight', 'backbone.model.blocks.5.attn.proj.bias', 'backbone.model.blocks.5.norm2.weight', 'backbone.model.blocks.5.norm2.bias', 'backbone.model.blocks.5.mlp.fc1.weight', 'backbone.model.blocks.5.mlp.fc1.bias', 'backbone.model.blocks.5.mlp.fc2.weight', 'backbone.model.blocks.5.mlp.fc2.bias', 'backbone.model.blocks.6.norm1.weight', 'backbone.model.blocks.6.norm1.bias', 'backbone.model.blocks.6.attn.qkv.weight', 'backbone.model.blocks.6.attn.qkv.bias', 'backbone.model.blocks.6.attn.proj.weight', 'backbone.model.blocks.6.attn.proj.bias', 'backbone.model.blocks.6.norm2.weight', 'backbone.model.blocks.6.norm2.bias', 'backbone.model.blocks.6.mlp.fc1.weight', 'backbone.model.blocks.6.mlp.fc1.bias', 'backbone.model.blocks.6.mlp.fc2.weight', 'backbone.model.blocks.6.mlp.fc2.bias', 'backbone.model.blocks.7.norm1.weight', 'backbone.model.blocks.7.norm1.bias', 'backbone.model.blocks.7.attn.qkv.weight', 'backbone.model.blocks.7.attn.qkv.bias', 'backbone.model.blocks.7.attn.proj.weight', 'backbone.model.blocks.7.attn.proj.bias', 'backbone.model.blocks.7.norm2.weight', 'backbone.model.blocks.7.norm2.bias', 'backbone.model.blocks.7.mlp.fc1.weight', 'backbone.model.blocks.7.mlp.fc1.bias', 'backbone.model.blocks.7.mlp.fc2.weight', 'backbone.model.blocks.7.mlp.fc2.bias', 'backbone.model.blocks.8.norm1.weight', 'backbone.model.blocks.8.norm1.bias', 'backbone.model.blocks.8.attn.qkv.weight', 'backbone.model.blocks.8.attn.qkv.bias', 'backbone.model.blocks.8.attn.proj.weight', 'backbone.model.blocks.8.attn.proj.bias', 'backbone.model.blocks.8.norm2.weight', 'backbone.model.blocks.8.norm2.bias', 'backbone.model.blocks.8.mlp.fc1.weight', 'backbone.model.blocks.8.mlp.fc1.bias', 'backbone.model.blocks.8.mlp.fc2.weight', 'backbone.model.blocks.8.mlp.fc2.bias', 'backbone.model.blocks.9.norm1.weight', 'backbone.model.blocks.9.norm1.bias', 'backbone.model.blocks.9.attn.qkv.weight', 'backbone.model.blocks.9.attn.qkv.bias', 'backbone.model.blocks.9.attn.proj.weight', 'backbone.model.blocks.9.attn.proj.bias', 'backbone.model.blocks.9.norm2.weight', 'backbone.model.blocks.9.norm2.bias', 'backbone.model.blocks.9.mlp.fc1.weight', 'backbone.model.blocks.9.mlp.fc1.bias', 'backbone.model.blocks.9.mlp.fc2.weight', 'backbone.model.blocks.9.mlp.fc2.bias', 'backbone.model.blocks.10.norm1.weight', 'backbone.model.blocks.10.norm1.bias', 'backbone.model.blocks.10.attn.qkv.weight', 'backbone.model.blocks.10.attn.qkv.bias', 'backbone.model.blocks.10.attn.proj.weight', 'backbone.model.blocks.10.attn.proj.bias', 'backbone.model.blocks.10.norm2.weight', 'backbone.model.blocks.10.norm2.bias', 'backbone.model.blocks.10.mlp.fc1.weight', 'backbone.model.blocks.10.mlp.fc1.bias', 'backbone.model.blocks.10.mlp.fc2.weight', 'backbone.model.blocks.10.mlp.fc2.bias', 'backbone.model.blocks.11.norm1.weight', 'backbone.model.blocks.11.norm1.bias', 'backbone.model.blocks.11.attn.qkv.weight', 'backbone.model.blocks.11.attn.qkv.bias', 'backbone.model.blocks.11.attn.proj.weight', 'backbone.model.blocks.11.attn.proj.bias', 'backbone.model.blocks.11.norm2.weight', 'backbone.model.blocks.11.norm2.bias', 'backbone.model.blocks.11.mlp.fc1.weight', 'backbone.model.blocks.11.mlp.fc1.bias', 'backbone.model.blocks.11.mlp.fc2.weight', 'backbone.model.blocks.11.mlp.fc2.bias', 'backbone.model.norm.weight', 'backbone.model.norm.bias']. Ignoring unexpected keys.\n"
     ]
    }
   ],
   "source": [
    "model = FromPretrained(\n",
    "    model=model,\n",
    "    ckpt_path=\"/workspaces/HIAAC-KR-Dev-Container/shared_data/seismic_foundation_model/pretrained_models/SFM-Base-512.pth\",\n",
    "    ckpt_key=\"model\",\n",
    "    strict=False,\n",
    "    filter_keys=[\"^blocks*\", \"^cls_token\", \"^pos_embed\", \"^patch_embed\", \"^norm\"],\n",
    "    keys_to_rename={\"\": \"backbone.model.\"},\n",
    "    ckpt_load_weights_only=False,\n",
    "    error_on_missing_keys=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/seed.py:42: No seed found, seed set to 0\n",
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log directory set to: /workspaces/HIAAC-KR-Dev-Container/Minerva-Dev/docs/notebooks/examples/seismic/facies_classification/parihaka/logs/f3_segmentation\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"./logs\"\n",
    "logger = CSVLogger(log_dir, name=\"dinov2\", version=\"parihaka\")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=2,\n",
    "    limit_train_batches=10,\n",
    "    limit_val_batches=10,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint],\n",
    ")\n",
    "\n",
    "pipeline = SimpleLightningPipeline(\n",
    "    model=model,\n",
    "    trainer=trainer,\n",
    "    log_dir=log_dir + \"/f3_segmentation\",\n",
    "    save_run_status=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/fabric/loggers/csv_logs.py:268: Experiment logs directory ./logs/dinov2/parihaka exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory ./logs/dinov2/parihaka/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Dev/docs/notebooks/examples/seismic/facies_classification/parihaka/logs/f3_segmentation/run_2024-12-05-00-13-2445e0ec351c4a4b709aebf4d6065b4054.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type              | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | backbone | VisionTransformer | 90.2 M | train\n",
      "1 | fc       | Identity          | 0      | train\n",
      "2 | loss_fn  | CrossEntropyLoss  | 0      | train\n",
      "-------------------------------------------------------\n",
      "90.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "90.2 M    Total params\n",
      "360.821   Total estimated model params size (MB)\n",
      "301       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 10/10 [00:02<00:00,  3.90it/s, v_num=haka, val_loss=2.160, train_loss=1.610]"
     ]
    }
   ],
   "source": [
    "pipeline.run(data_module, task=\"fit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
