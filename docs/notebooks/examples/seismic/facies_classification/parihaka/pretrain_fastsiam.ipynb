{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Example Notebook for pretreining: FASTSIAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:53: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import JaccardIndex\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from minerva.data.datasets.supervised_dataset import SupervisedReconstructionDataset\n",
    "from minerva.data.readers.png_reader import PNGReader\n",
    "from minerva.data.readers.tiff_reader import TiffReader\n",
    "from minerva.models.ssl.fastsiam import FastSiam  # Import TriBYOL from Minerva\n",
    "from minerva.transforms.transform import _Transform\n",
    "from minerva.pipelines.lightning_pipeline import SimpleLightningPipeline\n",
    "from minerva.data.data_modules.parihaka import ParihakaDataModule\n",
    "from minerva.transforms.transform import Padding\n",
    "from minerva.models.nets.image.deeplabv3 import DeepLabV3Backbone\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the training images and annotations\n",
    "train_path = \"/workspaces/Minerva-Dev/shared_data/seam_ai_datasets/seam_ai/images/\"\n",
    "annotation_path = \"/workspaces/Minerva-Dev/shared_data/seam_ai_datasets/seam_ai/annotations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a padding transformation to ensure consistent image sizes\n",
    "transform = Padding(1006, 590)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Parihaka DataModule for handling data loading and splitting\n",
    "data_module = ParihakaDataModule(\n",
    "    root_data_dir=train_path,\n",
    "    root_annotation_dir=annotation_path,\n",
    "    train_transforms=None,\n",
    "    batch_size=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DeepLabV3 backbone for feature extraction\n",
    "backbone = DeepLabV3Backbone()\n",
    "\n",
    "# Initialize the FastSiam model for self-supervised learning\n",
    "fastsiam_model = FastSiam(\n",
    "    backbone=backbone,     # Use DeepLabV3 as the backbone\n",
    "    in_dim=2048,           # Dimensionality of the input of the projection head\n",
    "    hid_dim=2048,           # Dimensionality of the hidden layer in the MLP\n",
    "    out_dim=2048,          # Dimensionality of the output of the prediction head\n",
    "    lr=1e-3,               # Learning rate for the optimizer\n",
    "    num_classes=6          # Number of classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define checkpoint location\n",
    "model_name = \"fastsiam\"\n",
    "ckpt_save_path = \"/workspaces/Minerva-Dev/checkpoints/\"\n",
    "\n",
    "# Define a checkpoint callback to save the best model based on validation loss\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=ckpt_save_path,                         # Directory to save the checkpoints\n",
    "    filename=model_name,                            # File name for the checkpoint\n",
    "    save_top_k=1,                                   # Save only the best model\n",
    "    monitor=\"val_loss\",                             # Monitor validation loss to determine the best model\n",
    "    mode=\"min\",                                     # Minimize validation loss\n",
    "    save_weights_only=False,                        # Save the entire model, not just weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Initialize the PyTorch Lightning Trainer\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=2,                   # Number of epochs to train\n",
    "    accelerator=\"gpu\",              # Use GPU for training\n",
    "    devices=1,                      # Number of GPUs to use\n",
    "    callbacks=[checkpoint_callback] # Include the checkpoint callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/seed.py:42: No seed found, seed set to 0\n",
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log directory set to: /workspaces/Minerva-Dev/docs/notebooks/examples/seismic/facies_classification/parihaka/lightning_logs/version_289\n"
     ]
    }
   ],
   "source": [
    "# Initialize the pipeline for training and testing\n",
    "pipeline = SimpleLightningPipeline(\n",
    "    model=fastsiam_model,  # FastSiam model for training\n",
    "    trainer=trainer,      # Trainer instance\n",
    "    save_run_status=True, # Save the status of the training run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /workspaces/Minerva-Dev/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline info saved at: /workspaces/Minerva-Dev/docs/notebooks/examples/seismic/facies_classification/parihaka/lightning_logs/version_289/run_2024-12-21-17-29-49bfc5004ea2164c468dc01df68124fcb4.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name                        | Type              | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0 | backbone                    | DeepLabV3Backbone | 25.6 M | train\n",
      "1 | prediction_branch_projector | SimSiamMLPHead    | 2.1 M  | train\n",
      "2 | prediction_branch_predictor | SimSiamMLPHead    | 8.4 M  | train\n",
      "3 | target_branch_backbone      | DeepLabV3Backbone | 25.6 M | train\n",
      "4 | target_branch_projector     | SimSiamMLPHead    | 8.4 M  | train\n",
      "5 | global_avg_pool             | AdaptiveAvgPool2d | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "70.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "70.0 M    Total params\n",
      "280.034   Total estimated model params size (MB)\n",
      "320       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 560/560 [10:42<00:00,  0.87it/s, v_num=289, train_loss_step=-.948, val_loss_step=-.547, val_loss_epoch=-.745, train_loss_epoch=-.884]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 560/560 [10:42<00:00,  0.87it/s, v_num=289, train_loss_step=-.948, val_loss_step=-.547, val_loss_epoch=-.745, train_loss_epoch=-.884]\n",
      "Pipeline info saved at: /workspaces/Minerva-Dev/docs/notebooks/examples/seismic/facies_classification/parihaka/lightning_logs/version_289/run_2024-12-21-17-29-49bfc5004ea2164c468dc01df68124fcb4.yaml\n"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "pipeline.run(data=data_module, task=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /workspaces/Minerva-Dev/checkpoints//fastsiam.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline info saved at: /workspaces/Minerva-Dev/docs/notebooks/examples/seismic/facies_classification/parihaka/lightning_logs/version_289/run_2024-12-21-17-29-49bfc5004ea2164c468dc01df68124fcb4.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /workspaces/Minerva-Dev/checkpoints//fastsiam.ckpt\n",
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 100/100 [01:07<00:00,  1.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_loss_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    -0.8782209753990173    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   -0.8782209753990173   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline info saved at: /workspaces/Minerva-Dev/docs/notebooks/examples/seismic/facies_classification/parihaka/lightning_logs/version_289/run_2024-12-21-17-29-49bfc5004ea2164c468dc01df68124fcb4.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': -0.8782209753990173}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and test from the best checkpoint\n",
    "pipeline.run(data=data_module, task=\"test\", ckpt_path=f\"{ckpt_save_path}/{model_name}.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
