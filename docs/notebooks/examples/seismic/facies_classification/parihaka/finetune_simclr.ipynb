{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tunning DeepLabV3 from SIMCLR on Parihaka Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:53: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from common import get_data_module, get_trainer_pipeline\n",
    "import torch\n",
    "from minerva.models.nets.image.deeplabv3 import DeepLabV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_dir = \"/workspaces/HIAAC-KR-Dev-Container/shared_data/seam_ai_datasets/seam_ai/images\"\n",
    "root_annotation_dir = \"/workspaces/HIAAC-KR-Dev-Container/shared_data/seam_ai_datasets/seam_ai/annotations\"\n",
    "ckpt_file = \"/workspaces/HIAAC-KR-Dev-Container/shared_data/notebooks_e_pesos/pesos/simclr.ckpt\"\n",
    "\n",
    "\n",
    "img_size = (1006, 590)          # Change this to the size of the images in the dataset\n",
    "model_name = \"simclr\"       # Model name (just identifier)\n",
    "dataset_name = \"seam_ai\"        # Dataset name (just identifier)\n",
    "single_channel = False          # If True, the model will be trained with single channel images (instead of 3 channels)\n",
    "\n",
    "log_dir = \"./logs\"              # Directory to save logs\n",
    "batch_size = 2                  # Batch size    \n",
    "seed = 42                       # Seed for reproducibility\n",
    "num_epochs = 100                # Number of epochs to train\n",
    "is_debug = True                 # If True, only 3 batch will be processed for 3 epochs\n",
    "accelerator = \"gpu\"             # CPU or GPU\n",
    "devices = 1                     # Num GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Module (do not change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataModule\n",
       "    Data: /workspaces/HIAAC-KR-Dev-Container/shared_data/seam_ai_datasets/seam_ai/images\n",
       "    Annotations: /workspaces/HIAAC-KR-Dev-Container/shared_data/seam_ai_datasets/seam_ai/annotations\n",
       "    Batch size: 2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = get_data_module(\n",
    "    root_data_dir=root_data_dir,\n",
    "    root_annotation_dir=root_annotation_dir,\n",
    "    img_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    single_channel=single_channel\n",
    ")\n",
    "\n",
    "data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 1006, 590]), torch.Size([2, 1, 1006, 590]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to check if the data module is working\n",
    "data_module.setup(\"fit\")\n",
    "train_batch_x, train_batch_y = next(iter(data_module.train_dataloader()))\n",
    "train_batch_x.shape, train_batch_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **** Create and Load model HERE ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepLabV3(\n",
       "  (backbone): DeepLabV3Backbone(\n",
       "    (RN50model): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): DeepLabV3PredictionHead(\n",
       "    (0): ASPP(\n",
       "      (convs): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (3): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (4): ASPPPooling(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepLabV3()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['backbone.RN50model.conv1.weight',\n",
       " 'backbone.RN50model.bn1.weight',\n",
       " 'backbone.RN50model.bn1.bias',\n",
       " 'backbone.RN50model.bn1.running_mean',\n",
       " 'backbone.RN50model.bn1.running_var',\n",
       " 'backbone.RN50model.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.0.conv1.weight',\n",
       " 'backbone.RN50model.layer1.0.bn1.weight',\n",
       " 'backbone.RN50model.layer1.0.bn1.bias',\n",
       " 'backbone.RN50model.layer1.0.bn1.running_mean',\n",
       " 'backbone.RN50model.layer1.0.bn1.running_var',\n",
       " 'backbone.RN50model.layer1.0.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.0.conv2.weight',\n",
       " 'backbone.RN50model.layer1.0.bn2.weight',\n",
       " 'backbone.RN50model.layer1.0.bn2.bias',\n",
       " 'backbone.RN50model.layer1.0.bn2.running_mean',\n",
       " 'backbone.RN50model.layer1.0.bn2.running_var',\n",
       " 'backbone.RN50model.layer1.0.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.0.conv3.weight',\n",
       " 'backbone.RN50model.layer1.0.bn3.weight',\n",
       " 'backbone.RN50model.layer1.0.bn3.bias',\n",
       " 'backbone.RN50model.layer1.0.bn3.running_mean',\n",
       " 'backbone.RN50model.layer1.0.bn3.running_var',\n",
       " 'backbone.RN50model.layer1.0.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.0.downsample.0.weight',\n",
       " 'backbone.RN50model.layer1.0.downsample.1.weight',\n",
       " 'backbone.RN50model.layer1.0.downsample.1.bias',\n",
       " 'backbone.RN50model.layer1.0.downsample.1.running_mean',\n",
       " 'backbone.RN50model.layer1.0.downsample.1.running_var',\n",
       " 'backbone.RN50model.layer1.0.downsample.1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.1.conv1.weight',\n",
       " 'backbone.RN50model.layer1.1.bn1.weight',\n",
       " 'backbone.RN50model.layer1.1.bn1.bias',\n",
       " 'backbone.RN50model.layer1.1.bn1.running_mean',\n",
       " 'backbone.RN50model.layer1.1.bn1.running_var',\n",
       " 'backbone.RN50model.layer1.1.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.1.conv2.weight',\n",
       " 'backbone.RN50model.layer1.1.bn2.weight',\n",
       " 'backbone.RN50model.layer1.1.bn2.bias',\n",
       " 'backbone.RN50model.layer1.1.bn2.running_mean',\n",
       " 'backbone.RN50model.layer1.1.bn2.running_var',\n",
       " 'backbone.RN50model.layer1.1.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.1.conv3.weight',\n",
       " 'backbone.RN50model.layer1.1.bn3.weight',\n",
       " 'backbone.RN50model.layer1.1.bn3.bias',\n",
       " 'backbone.RN50model.layer1.1.bn3.running_mean',\n",
       " 'backbone.RN50model.layer1.1.bn3.running_var',\n",
       " 'backbone.RN50model.layer1.1.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.2.conv1.weight',\n",
       " 'backbone.RN50model.layer1.2.bn1.weight',\n",
       " 'backbone.RN50model.layer1.2.bn1.bias',\n",
       " 'backbone.RN50model.layer1.2.bn1.running_mean',\n",
       " 'backbone.RN50model.layer1.2.bn1.running_var',\n",
       " 'backbone.RN50model.layer1.2.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.2.conv2.weight',\n",
       " 'backbone.RN50model.layer1.2.bn2.weight',\n",
       " 'backbone.RN50model.layer1.2.bn2.bias',\n",
       " 'backbone.RN50model.layer1.2.bn2.running_mean',\n",
       " 'backbone.RN50model.layer1.2.bn2.running_var',\n",
       " 'backbone.RN50model.layer1.2.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.2.conv3.weight',\n",
       " 'backbone.RN50model.layer1.2.bn3.weight',\n",
       " 'backbone.RN50model.layer1.2.bn3.bias',\n",
       " 'backbone.RN50model.layer1.2.bn3.running_mean',\n",
       " 'backbone.RN50model.layer1.2.bn3.running_var',\n",
       " 'backbone.RN50model.layer1.2.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.0.conv1.weight',\n",
       " 'backbone.RN50model.layer2.0.bn1.weight',\n",
       " 'backbone.RN50model.layer2.0.bn1.bias',\n",
       " 'backbone.RN50model.layer2.0.bn1.running_mean',\n",
       " 'backbone.RN50model.layer2.0.bn1.running_var',\n",
       " 'backbone.RN50model.layer2.0.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.0.conv2.weight',\n",
       " 'backbone.RN50model.layer2.0.bn2.weight',\n",
       " 'backbone.RN50model.layer2.0.bn2.bias',\n",
       " 'backbone.RN50model.layer2.0.bn2.running_mean',\n",
       " 'backbone.RN50model.layer2.0.bn2.running_var',\n",
       " 'backbone.RN50model.layer2.0.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.0.conv3.weight',\n",
       " 'backbone.RN50model.layer2.0.bn3.weight',\n",
       " 'backbone.RN50model.layer2.0.bn3.bias',\n",
       " 'backbone.RN50model.layer2.0.bn3.running_mean',\n",
       " 'backbone.RN50model.layer2.0.bn3.running_var',\n",
       " 'backbone.RN50model.layer2.0.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.0.downsample.0.weight',\n",
       " 'backbone.RN50model.layer2.0.downsample.1.weight',\n",
       " 'backbone.RN50model.layer2.0.downsample.1.bias',\n",
       " 'backbone.RN50model.layer2.0.downsample.1.running_mean',\n",
       " 'backbone.RN50model.layer2.0.downsample.1.running_var',\n",
       " 'backbone.RN50model.layer2.0.downsample.1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.1.conv1.weight',\n",
       " 'backbone.RN50model.layer2.1.bn1.weight',\n",
       " 'backbone.RN50model.layer2.1.bn1.bias',\n",
       " 'backbone.RN50model.layer2.1.bn1.running_mean',\n",
       " 'backbone.RN50model.layer2.1.bn1.running_var',\n",
       " 'backbone.RN50model.layer2.1.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.1.conv2.weight',\n",
       " 'backbone.RN50model.layer2.1.bn2.weight',\n",
       " 'backbone.RN50model.layer2.1.bn2.bias',\n",
       " 'backbone.RN50model.layer2.1.bn2.running_mean',\n",
       " 'backbone.RN50model.layer2.1.bn2.running_var',\n",
       " 'backbone.RN50model.layer2.1.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.1.conv3.weight',\n",
       " 'backbone.RN50model.layer2.1.bn3.weight',\n",
       " 'backbone.RN50model.layer2.1.bn3.bias',\n",
       " 'backbone.RN50model.layer2.1.bn3.running_mean',\n",
       " 'backbone.RN50model.layer2.1.bn3.running_var',\n",
       " 'backbone.RN50model.layer2.1.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.2.conv1.weight',\n",
       " 'backbone.RN50model.layer2.2.bn1.weight',\n",
       " 'backbone.RN50model.layer2.2.bn1.bias',\n",
       " 'backbone.RN50model.layer2.2.bn1.running_mean',\n",
       " 'backbone.RN50model.layer2.2.bn1.running_var',\n",
       " 'backbone.RN50model.layer2.2.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.2.conv2.weight',\n",
       " 'backbone.RN50model.layer2.2.bn2.weight',\n",
       " 'backbone.RN50model.layer2.2.bn2.bias',\n",
       " 'backbone.RN50model.layer2.2.bn2.running_mean',\n",
       " 'backbone.RN50model.layer2.2.bn2.running_var',\n",
       " 'backbone.RN50model.layer2.2.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.2.conv3.weight',\n",
       " 'backbone.RN50model.layer2.2.bn3.weight',\n",
       " 'backbone.RN50model.layer2.2.bn3.bias',\n",
       " 'backbone.RN50model.layer2.2.bn3.running_mean',\n",
       " 'backbone.RN50model.layer2.2.bn3.running_var',\n",
       " 'backbone.RN50model.layer2.2.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.3.conv1.weight',\n",
       " 'backbone.RN50model.layer2.3.bn1.weight',\n",
       " 'backbone.RN50model.layer2.3.bn1.bias',\n",
       " 'backbone.RN50model.layer2.3.bn1.running_mean',\n",
       " 'backbone.RN50model.layer2.3.bn1.running_var',\n",
       " 'backbone.RN50model.layer2.3.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.3.conv2.weight',\n",
       " 'backbone.RN50model.layer2.3.bn2.weight',\n",
       " 'backbone.RN50model.layer2.3.bn2.bias',\n",
       " 'backbone.RN50model.layer2.3.bn2.running_mean',\n",
       " 'backbone.RN50model.layer2.3.bn2.running_var',\n",
       " 'backbone.RN50model.layer2.3.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.3.conv3.weight',\n",
       " 'backbone.RN50model.layer2.3.bn3.weight',\n",
       " 'backbone.RN50model.layer2.3.bn3.bias',\n",
       " 'backbone.RN50model.layer2.3.bn3.running_mean',\n",
       " 'backbone.RN50model.layer2.3.bn3.running_var',\n",
       " 'backbone.RN50model.layer2.3.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.0.conv1.weight',\n",
       " 'backbone.RN50model.layer3.0.bn1.weight',\n",
       " 'backbone.RN50model.layer3.0.bn1.bias',\n",
       " 'backbone.RN50model.layer3.0.bn1.running_mean',\n",
       " 'backbone.RN50model.layer3.0.bn1.running_var',\n",
       " 'backbone.RN50model.layer3.0.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.0.conv2.weight',\n",
       " 'backbone.RN50model.layer3.0.bn2.weight',\n",
       " 'backbone.RN50model.layer3.0.bn2.bias',\n",
       " 'backbone.RN50model.layer3.0.bn2.running_mean',\n",
       " 'backbone.RN50model.layer3.0.bn2.running_var',\n",
       " 'backbone.RN50model.layer3.0.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.0.conv3.weight',\n",
       " 'backbone.RN50model.layer3.0.bn3.weight',\n",
       " 'backbone.RN50model.layer3.0.bn3.bias',\n",
       " 'backbone.RN50model.layer3.0.bn3.running_mean',\n",
       " 'backbone.RN50model.layer3.0.bn3.running_var',\n",
       " 'backbone.RN50model.layer3.0.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.0.downsample.0.weight',\n",
       " 'backbone.RN50model.layer3.0.downsample.1.weight',\n",
       " 'backbone.RN50model.layer3.0.downsample.1.bias',\n",
       " 'backbone.RN50model.layer3.0.downsample.1.running_mean',\n",
       " 'backbone.RN50model.layer3.0.downsample.1.running_var',\n",
       " 'backbone.RN50model.layer3.0.downsample.1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.1.conv1.weight',\n",
       " 'backbone.RN50model.layer3.1.bn1.weight',\n",
       " 'backbone.RN50model.layer3.1.bn1.bias',\n",
       " 'backbone.RN50model.layer3.1.bn1.running_mean',\n",
       " 'backbone.RN50model.layer3.1.bn1.running_var',\n",
       " 'backbone.RN50model.layer3.1.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.1.conv2.weight',\n",
       " 'backbone.RN50model.layer3.1.bn2.weight',\n",
       " 'backbone.RN50model.layer3.1.bn2.bias',\n",
       " 'backbone.RN50model.layer3.1.bn2.running_mean',\n",
       " 'backbone.RN50model.layer3.1.bn2.running_var',\n",
       " 'backbone.RN50model.layer3.1.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.1.conv3.weight',\n",
       " 'backbone.RN50model.layer3.1.bn3.weight',\n",
       " 'backbone.RN50model.layer3.1.bn3.bias',\n",
       " 'backbone.RN50model.layer3.1.bn3.running_mean',\n",
       " 'backbone.RN50model.layer3.1.bn3.running_var',\n",
       " 'backbone.RN50model.layer3.1.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.2.conv1.weight',\n",
       " 'backbone.RN50model.layer3.2.bn1.weight',\n",
       " 'backbone.RN50model.layer3.2.bn1.bias',\n",
       " 'backbone.RN50model.layer3.2.bn1.running_mean',\n",
       " 'backbone.RN50model.layer3.2.bn1.running_var',\n",
       " 'backbone.RN50model.layer3.2.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.2.conv2.weight',\n",
       " 'backbone.RN50model.layer3.2.bn2.weight',\n",
       " 'backbone.RN50model.layer3.2.bn2.bias',\n",
       " 'backbone.RN50model.layer3.2.bn2.running_mean',\n",
       " 'backbone.RN50model.layer3.2.bn2.running_var',\n",
       " 'backbone.RN50model.layer3.2.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.2.conv3.weight',\n",
       " 'backbone.RN50model.layer3.2.bn3.weight',\n",
       " 'backbone.RN50model.layer3.2.bn3.bias',\n",
       " 'backbone.RN50model.layer3.2.bn3.running_mean',\n",
       " 'backbone.RN50model.layer3.2.bn3.running_var',\n",
       " 'backbone.RN50model.layer3.2.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.3.conv1.weight',\n",
       " 'backbone.RN50model.layer3.3.bn1.weight',\n",
       " 'backbone.RN50model.layer3.3.bn1.bias',\n",
       " 'backbone.RN50model.layer3.3.bn1.running_mean',\n",
       " 'backbone.RN50model.layer3.3.bn1.running_var',\n",
       " 'backbone.RN50model.layer3.3.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.3.conv2.weight',\n",
       " 'backbone.RN50model.layer3.3.bn2.weight',\n",
       " 'backbone.RN50model.layer3.3.bn2.bias',\n",
       " 'backbone.RN50model.layer3.3.bn2.running_mean',\n",
       " 'backbone.RN50model.layer3.3.bn2.running_var',\n",
       " 'backbone.RN50model.layer3.3.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.3.conv3.weight',\n",
       " 'backbone.RN50model.layer3.3.bn3.weight',\n",
       " 'backbone.RN50model.layer3.3.bn3.bias',\n",
       " 'backbone.RN50model.layer3.3.bn3.running_mean',\n",
       " 'backbone.RN50model.layer3.3.bn3.running_var',\n",
       " 'backbone.RN50model.layer3.3.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.4.conv1.weight',\n",
       " 'backbone.RN50model.layer3.4.bn1.weight',\n",
       " 'backbone.RN50model.layer3.4.bn1.bias',\n",
       " 'backbone.RN50model.layer3.4.bn1.running_mean',\n",
       " 'backbone.RN50model.layer3.4.bn1.running_var',\n",
       " 'backbone.RN50model.layer3.4.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.4.conv2.weight',\n",
       " 'backbone.RN50model.layer3.4.bn2.weight',\n",
       " 'backbone.RN50model.layer3.4.bn2.bias',\n",
       " 'backbone.RN50model.layer3.4.bn2.running_mean',\n",
       " 'backbone.RN50model.layer3.4.bn2.running_var',\n",
       " 'backbone.RN50model.layer3.4.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.4.conv3.weight',\n",
       " 'backbone.RN50model.layer3.4.bn3.weight',\n",
       " 'backbone.RN50model.layer3.4.bn3.bias',\n",
       " 'backbone.RN50model.layer3.4.bn3.running_mean',\n",
       " 'backbone.RN50model.layer3.4.bn3.running_var',\n",
       " 'backbone.RN50model.layer3.4.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.5.conv1.weight',\n",
       " 'backbone.RN50model.layer3.5.bn1.weight',\n",
       " 'backbone.RN50model.layer3.5.bn1.bias',\n",
       " 'backbone.RN50model.layer3.5.bn1.running_mean',\n",
       " 'backbone.RN50model.layer3.5.bn1.running_var',\n",
       " 'backbone.RN50model.layer3.5.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.5.conv2.weight',\n",
       " 'backbone.RN50model.layer3.5.bn2.weight',\n",
       " 'backbone.RN50model.layer3.5.bn2.bias',\n",
       " 'backbone.RN50model.layer3.5.bn2.running_mean',\n",
       " 'backbone.RN50model.layer3.5.bn2.running_var',\n",
       " 'backbone.RN50model.layer3.5.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.5.conv3.weight',\n",
       " 'backbone.RN50model.layer3.5.bn3.weight',\n",
       " 'backbone.RN50model.layer3.5.bn3.bias',\n",
       " 'backbone.RN50model.layer3.5.bn3.running_mean',\n",
       " 'backbone.RN50model.layer3.5.bn3.running_var',\n",
       " 'backbone.RN50model.layer3.5.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.0.conv1.weight',\n",
       " 'backbone.RN50model.layer4.0.bn1.weight',\n",
       " 'backbone.RN50model.layer4.0.bn1.bias',\n",
       " 'backbone.RN50model.layer4.0.bn1.running_mean',\n",
       " 'backbone.RN50model.layer4.0.bn1.running_var',\n",
       " 'backbone.RN50model.layer4.0.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.0.conv2.weight',\n",
       " 'backbone.RN50model.layer4.0.bn2.weight',\n",
       " 'backbone.RN50model.layer4.0.bn2.bias',\n",
       " 'backbone.RN50model.layer4.0.bn2.running_mean',\n",
       " 'backbone.RN50model.layer4.0.bn2.running_var',\n",
       " 'backbone.RN50model.layer4.0.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.0.conv3.weight',\n",
       " 'backbone.RN50model.layer4.0.bn3.weight',\n",
       " 'backbone.RN50model.layer4.0.bn3.bias',\n",
       " 'backbone.RN50model.layer4.0.bn3.running_mean',\n",
       " 'backbone.RN50model.layer4.0.bn3.running_var',\n",
       " 'backbone.RN50model.layer4.0.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.0.downsample.0.weight',\n",
       " 'backbone.RN50model.layer4.0.downsample.1.weight',\n",
       " 'backbone.RN50model.layer4.0.downsample.1.bias',\n",
       " 'backbone.RN50model.layer4.0.downsample.1.running_mean',\n",
       " 'backbone.RN50model.layer4.0.downsample.1.running_var',\n",
       " 'backbone.RN50model.layer4.0.downsample.1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.1.conv1.weight',\n",
       " 'backbone.RN50model.layer4.1.bn1.weight',\n",
       " 'backbone.RN50model.layer4.1.bn1.bias',\n",
       " 'backbone.RN50model.layer4.1.bn1.running_mean',\n",
       " 'backbone.RN50model.layer4.1.bn1.running_var',\n",
       " 'backbone.RN50model.layer4.1.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.1.conv2.weight',\n",
       " 'backbone.RN50model.layer4.1.bn2.weight',\n",
       " 'backbone.RN50model.layer4.1.bn2.bias',\n",
       " 'backbone.RN50model.layer4.1.bn2.running_mean',\n",
       " 'backbone.RN50model.layer4.1.bn2.running_var',\n",
       " 'backbone.RN50model.layer4.1.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.1.conv3.weight',\n",
       " 'backbone.RN50model.layer4.1.bn3.weight',\n",
       " 'backbone.RN50model.layer4.1.bn3.bias',\n",
       " 'backbone.RN50model.layer4.1.bn3.running_mean',\n",
       " 'backbone.RN50model.layer4.1.bn3.running_var',\n",
       " 'backbone.RN50model.layer4.1.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.2.conv1.weight',\n",
       " 'backbone.RN50model.layer4.2.bn1.weight',\n",
       " 'backbone.RN50model.layer4.2.bn1.bias',\n",
       " 'backbone.RN50model.layer4.2.bn1.running_mean',\n",
       " 'backbone.RN50model.layer4.2.bn1.running_var',\n",
       " 'backbone.RN50model.layer4.2.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.2.conv2.weight',\n",
       " 'backbone.RN50model.layer4.2.bn2.weight',\n",
       " 'backbone.RN50model.layer4.2.bn2.bias',\n",
       " 'backbone.RN50model.layer4.2.bn2.running_mean',\n",
       " 'backbone.RN50model.layer4.2.bn2.running_var',\n",
       " 'backbone.RN50model.layer4.2.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.2.conv3.weight',\n",
       " 'backbone.RN50model.layer4.2.bn3.weight',\n",
       " 'backbone.RN50model.layer4.2.bn3.bias',\n",
       " 'backbone.RN50model.layer4.2.bn3.running_mean',\n",
       " 'backbone.RN50model.layer4.2.bn3.running_var',\n",
       " 'backbone.RN50model.layer4.2.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.fc.weight',\n",
       " 'backbone.RN50model.fc.bias',\n",
       " 'fc.0.convs.0.0.weight',\n",
       " 'fc.0.convs.0.1.weight',\n",
       " 'fc.0.convs.0.1.bias',\n",
       " 'fc.0.convs.0.1.running_mean',\n",
       " 'fc.0.convs.0.1.running_var',\n",
       " 'fc.0.convs.0.1.num_batches_tracked',\n",
       " 'fc.0.convs.1.0.weight',\n",
       " 'fc.0.convs.1.1.weight',\n",
       " 'fc.0.convs.1.1.bias',\n",
       " 'fc.0.convs.1.1.running_mean',\n",
       " 'fc.0.convs.1.1.running_var',\n",
       " 'fc.0.convs.1.1.num_batches_tracked',\n",
       " 'fc.0.convs.2.0.weight',\n",
       " 'fc.0.convs.2.1.weight',\n",
       " 'fc.0.convs.2.1.bias',\n",
       " 'fc.0.convs.2.1.running_mean',\n",
       " 'fc.0.convs.2.1.running_var',\n",
       " 'fc.0.convs.2.1.num_batches_tracked',\n",
       " 'fc.0.convs.3.0.weight',\n",
       " 'fc.0.convs.3.1.weight',\n",
       " 'fc.0.convs.3.1.bias',\n",
       " 'fc.0.convs.3.1.running_mean',\n",
       " 'fc.0.convs.3.1.running_var',\n",
       " 'fc.0.convs.3.1.num_batches_tracked',\n",
       " 'fc.0.convs.4.1.weight',\n",
       " 'fc.0.convs.4.2.weight',\n",
       " 'fc.0.convs.4.2.bias',\n",
       " 'fc.0.convs.4.2.running_mean',\n",
       " 'fc.0.convs.4.2.running_var',\n",
       " 'fc.0.convs.4.2.num_batches_tracked',\n",
       " 'fc.0.project.0.weight',\n",
       " 'fc.0.project.1.weight',\n",
       " 'fc.0.project.1.bias',\n",
       " 'fc.0.project.1.running_mean',\n",
       " 'fc.0.project.1.running_var',\n",
       " 'fc.0.project.1.num_batches_tracked',\n",
       " 'fc.1.weight',\n",
       " 'fc.2.weight',\n",
       " 'fc.2.bias',\n",
       " 'fc.2.running_mean',\n",
       " 'fc.2.running_var',\n",
       " 'fc.2.num_batches_tracked',\n",
       " 'fc.4.weight',\n",
       " 'fc.4.bias']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_717459/587373324.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(ckpt_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['backbone.RN50model.conv1.weight',\n",
       " 'backbone.RN50model.bn1.weight',\n",
       " 'backbone.RN50model.bn1.bias',\n",
       " 'backbone.RN50model.bn1.running_mean',\n",
       " 'backbone.RN50model.bn1.running_var',\n",
       " 'backbone.RN50model.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.0.conv1.weight',\n",
       " 'backbone.RN50model.layer1.0.bn1.weight',\n",
       " 'backbone.RN50model.layer1.0.bn1.bias',\n",
       " 'backbone.RN50model.layer1.0.bn1.running_mean',\n",
       " 'backbone.RN50model.layer1.0.bn1.running_var',\n",
       " 'backbone.RN50model.layer1.0.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.0.conv2.weight',\n",
       " 'backbone.RN50model.layer1.0.bn2.weight',\n",
       " 'backbone.RN50model.layer1.0.bn2.bias',\n",
       " 'backbone.RN50model.layer1.0.bn2.running_mean',\n",
       " 'backbone.RN50model.layer1.0.bn2.running_var',\n",
       " 'backbone.RN50model.layer1.0.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.0.conv3.weight',\n",
       " 'backbone.RN50model.layer1.0.bn3.weight',\n",
       " 'backbone.RN50model.layer1.0.bn3.bias',\n",
       " 'backbone.RN50model.layer1.0.bn3.running_mean',\n",
       " 'backbone.RN50model.layer1.0.bn3.running_var',\n",
       " 'backbone.RN50model.layer1.0.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.0.downsample.0.weight',\n",
       " 'backbone.RN50model.layer1.0.downsample.1.weight',\n",
       " 'backbone.RN50model.layer1.0.downsample.1.bias',\n",
       " 'backbone.RN50model.layer1.0.downsample.1.running_mean',\n",
       " 'backbone.RN50model.layer1.0.downsample.1.running_var',\n",
       " 'backbone.RN50model.layer1.0.downsample.1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.1.conv1.weight',\n",
       " 'backbone.RN50model.layer1.1.bn1.weight',\n",
       " 'backbone.RN50model.layer1.1.bn1.bias',\n",
       " 'backbone.RN50model.layer1.1.bn1.running_mean',\n",
       " 'backbone.RN50model.layer1.1.bn1.running_var',\n",
       " 'backbone.RN50model.layer1.1.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.1.conv2.weight',\n",
       " 'backbone.RN50model.layer1.1.bn2.weight',\n",
       " 'backbone.RN50model.layer1.1.bn2.bias',\n",
       " 'backbone.RN50model.layer1.1.bn2.running_mean',\n",
       " 'backbone.RN50model.layer1.1.bn2.running_var',\n",
       " 'backbone.RN50model.layer1.1.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.1.conv3.weight',\n",
       " 'backbone.RN50model.layer1.1.bn3.weight',\n",
       " 'backbone.RN50model.layer1.1.bn3.bias',\n",
       " 'backbone.RN50model.layer1.1.bn3.running_mean',\n",
       " 'backbone.RN50model.layer1.1.bn3.running_var',\n",
       " 'backbone.RN50model.layer1.1.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.2.conv1.weight',\n",
       " 'backbone.RN50model.layer1.2.bn1.weight',\n",
       " 'backbone.RN50model.layer1.2.bn1.bias',\n",
       " 'backbone.RN50model.layer1.2.bn1.running_mean',\n",
       " 'backbone.RN50model.layer1.2.bn1.running_var',\n",
       " 'backbone.RN50model.layer1.2.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.2.conv2.weight',\n",
       " 'backbone.RN50model.layer1.2.bn2.weight',\n",
       " 'backbone.RN50model.layer1.2.bn2.bias',\n",
       " 'backbone.RN50model.layer1.2.bn2.running_mean',\n",
       " 'backbone.RN50model.layer1.2.bn2.running_var',\n",
       " 'backbone.RN50model.layer1.2.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer1.2.conv3.weight',\n",
       " 'backbone.RN50model.layer1.2.bn3.weight',\n",
       " 'backbone.RN50model.layer1.2.bn3.bias',\n",
       " 'backbone.RN50model.layer1.2.bn3.running_mean',\n",
       " 'backbone.RN50model.layer1.2.bn3.running_var',\n",
       " 'backbone.RN50model.layer1.2.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.0.conv1.weight',\n",
       " 'backbone.RN50model.layer2.0.bn1.weight',\n",
       " 'backbone.RN50model.layer2.0.bn1.bias',\n",
       " 'backbone.RN50model.layer2.0.bn1.running_mean',\n",
       " 'backbone.RN50model.layer2.0.bn1.running_var',\n",
       " 'backbone.RN50model.layer2.0.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.0.conv2.weight',\n",
       " 'backbone.RN50model.layer2.0.bn2.weight',\n",
       " 'backbone.RN50model.layer2.0.bn2.bias',\n",
       " 'backbone.RN50model.layer2.0.bn2.running_mean',\n",
       " 'backbone.RN50model.layer2.0.bn2.running_var',\n",
       " 'backbone.RN50model.layer2.0.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.0.conv3.weight',\n",
       " 'backbone.RN50model.layer2.0.bn3.weight',\n",
       " 'backbone.RN50model.layer2.0.bn3.bias',\n",
       " 'backbone.RN50model.layer2.0.bn3.running_mean',\n",
       " 'backbone.RN50model.layer2.0.bn3.running_var',\n",
       " 'backbone.RN50model.layer2.0.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.0.downsample.0.weight',\n",
       " 'backbone.RN50model.layer2.0.downsample.1.weight',\n",
       " 'backbone.RN50model.layer2.0.downsample.1.bias',\n",
       " 'backbone.RN50model.layer2.0.downsample.1.running_mean',\n",
       " 'backbone.RN50model.layer2.0.downsample.1.running_var',\n",
       " 'backbone.RN50model.layer2.0.downsample.1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.1.conv1.weight',\n",
       " 'backbone.RN50model.layer2.1.bn1.weight',\n",
       " 'backbone.RN50model.layer2.1.bn1.bias',\n",
       " 'backbone.RN50model.layer2.1.bn1.running_mean',\n",
       " 'backbone.RN50model.layer2.1.bn1.running_var',\n",
       " 'backbone.RN50model.layer2.1.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.1.conv2.weight',\n",
       " 'backbone.RN50model.layer2.1.bn2.weight',\n",
       " 'backbone.RN50model.layer2.1.bn2.bias',\n",
       " 'backbone.RN50model.layer2.1.bn2.running_mean',\n",
       " 'backbone.RN50model.layer2.1.bn2.running_var',\n",
       " 'backbone.RN50model.layer2.1.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.1.conv3.weight',\n",
       " 'backbone.RN50model.layer2.1.bn3.weight',\n",
       " 'backbone.RN50model.layer2.1.bn3.bias',\n",
       " 'backbone.RN50model.layer2.1.bn3.running_mean',\n",
       " 'backbone.RN50model.layer2.1.bn3.running_var',\n",
       " 'backbone.RN50model.layer2.1.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.2.conv1.weight',\n",
       " 'backbone.RN50model.layer2.2.bn1.weight',\n",
       " 'backbone.RN50model.layer2.2.bn1.bias',\n",
       " 'backbone.RN50model.layer2.2.bn1.running_mean',\n",
       " 'backbone.RN50model.layer2.2.bn1.running_var',\n",
       " 'backbone.RN50model.layer2.2.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.2.conv2.weight',\n",
       " 'backbone.RN50model.layer2.2.bn2.weight',\n",
       " 'backbone.RN50model.layer2.2.bn2.bias',\n",
       " 'backbone.RN50model.layer2.2.bn2.running_mean',\n",
       " 'backbone.RN50model.layer2.2.bn2.running_var',\n",
       " 'backbone.RN50model.layer2.2.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.2.conv3.weight',\n",
       " 'backbone.RN50model.layer2.2.bn3.weight',\n",
       " 'backbone.RN50model.layer2.2.bn3.bias',\n",
       " 'backbone.RN50model.layer2.2.bn3.running_mean',\n",
       " 'backbone.RN50model.layer2.2.bn3.running_var',\n",
       " 'backbone.RN50model.layer2.2.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.3.conv1.weight',\n",
       " 'backbone.RN50model.layer2.3.bn1.weight',\n",
       " 'backbone.RN50model.layer2.3.bn1.bias',\n",
       " 'backbone.RN50model.layer2.3.bn1.running_mean',\n",
       " 'backbone.RN50model.layer2.3.bn1.running_var',\n",
       " 'backbone.RN50model.layer2.3.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.3.conv2.weight',\n",
       " 'backbone.RN50model.layer2.3.bn2.weight',\n",
       " 'backbone.RN50model.layer2.3.bn2.bias',\n",
       " 'backbone.RN50model.layer2.3.bn2.running_mean',\n",
       " 'backbone.RN50model.layer2.3.bn2.running_var',\n",
       " 'backbone.RN50model.layer2.3.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer2.3.conv3.weight',\n",
       " 'backbone.RN50model.layer2.3.bn3.weight',\n",
       " 'backbone.RN50model.layer2.3.bn3.bias',\n",
       " 'backbone.RN50model.layer2.3.bn3.running_mean',\n",
       " 'backbone.RN50model.layer2.3.bn3.running_var',\n",
       " 'backbone.RN50model.layer2.3.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.0.conv1.weight',\n",
       " 'backbone.RN50model.layer3.0.bn1.weight',\n",
       " 'backbone.RN50model.layer3.0.bn1.bias',\n",
       " 'backbone.RN50model.layer3.0.bn1.running_mean',\n",
       " 'backbone.RN50model.layer3.0.bn1.running_var',\n",
       " 'backbone.RN50model.layer3.0.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.0.conv2.weight',\n",
       " 'backbone.RN50model.layer3.0.bn2.weight',\n",
       " 'backbone.RN50model.layer3.0.bn2.bias',\n",
       " 'backbone.RN50model.layer3.0.bn2.running_mean',\n",
       " 'backbone.RN50model.layer3.0.bn2.running_var',\n",
       " 'backbone.RN50model.layer3.0.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.0.conv3.weight',\n",
       " 'backbone.RN50model.layer3.0.bn3.weight',\n",
       " 'backbone.RN50model.layer3.0.bn3.bias',\n",
       " 'backbone.RN50model.layer3.0.bn3.running_mean',\n",
       " 'backbone.RN50model.layer3.0.bn3.running_var',\n",
       " 'backbone.RN50model.layer3.0.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.0.downsample.0.weight',\n",
       " 'backbone.RN50model.layer3.0.downsample.1.weight',\n",
       " 'backbone.RN50model.layer3.0.downsample.1.bias',\n",
       " 'backbone.RN50model.layer3.0.downsample.1.running_mean',\n",
       " 'backbone.RN50model.layer3.0.downsample.1.running_var',\n",
       " 'backbone.RN50model.layer3.0.downsample.1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.1.conv1.weight',\n",
       " 'backbone.RN50model.layer3.1.bn1.weight',\n",
       " 'backbone.RN50model.layer3.1.bn1.bias',\n",
       " 'backbone.RN50model.layer3.1.bn1.running_mean',\n",
       " 'backbone.RN50model.layer3.1.bn1.running_var',\n",
       " 'backbone.RN50model.layer3.1.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.1.conv2.weight',\n",
       " 'backbone.RN50model.layer3.1.bn2.weight',\n",
       " 'backbone.RN50model.layer3.1.bn2.bias',\n",
       " 'backbone.RN50model.layer3.1.bn2.running_mean',\n",
       " 'backbone.RN50model.layer3.1.bn2.running_var',\n",
       " 'backbone.RN50model.layer3.1.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.1.conv3.weight',\n",
       " 'backbone.RN50model.layer3.1.bn3.weight',\n",
       " 'backbone.RN50model.layer3.1.bn3.bias',\n",
       " 'backbone.RN50model.layer3.1.bn3.running_mean',\n",
       " 'backbone.RN50model.layer3.1.bn3.running_var',\n",
       " 'backbone.RN50model.layer3.1.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.2.conv1.weight',\n",
       " 'backbone.RN50model.layer3.2.bn1.weight',\n",
       " 'backbone.RN50model.layer3.2.bn1.bias',\n",
       " 'backbone.RN50model.layer3.2.bn1.running_mean',\n",
       " 'backbone.RN50model.layer3.2.bn1.running_var',\n",
       " 'backbone.RN50model.layer3.2.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.2.conv2.weight',\n",
       " 'backbone.RN50model.layer3.2.bn2.weight',\n",
       " 'backbone.RN50model.layer3.2.bn2.bias',\n",
       " 'backbone.RN50model.layer3.2.bn2.running_mean',\n",
       " 'backbone.RN50model.layer3.2.bn2.running_var',\n",
       " 'backbone.RN50model.layer3.2.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.2.conv3.weight',\n",
       " 'backbone.RN50model.layer3.2.bn3.weight',\n",
       " 'backbone.RN50model.layer3.2.bn3.bias',\n",
       " 'backbone.RN50model.layer3.2.bn3.running_mean',\n",
       " 'backbone.RN50model.layer3.2.bn3.running_var',\n",
       " 'backbone.RN50model.layer3.2.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.3.conv1.weight',\n",
       " 'backbone.RN50model.layer3.3.bn1.weight',\n",
       " 'backbone.RN50model.layer3.3.bn1.bias',\n",
       " 'backbone.RN50model.layer3.3.bn1.running_mean',\n",
       " 'backbone.RN50model.layer3.3.bn1.running_var',\n",
       " 'backbone.RN50model.layer3.3.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.3.conv2.weight',\n",
       " 'backbone.RN50model.layer3.3.bn2.weight',\n",
       " 'backbone.RN50model.layer3.3.bn2.bias',\n",
       " 'backbone.RN50model.layer3.3.bn2.running_mean',\n",
       " 'backbone.RN50model.layer3.3.bn2.running_var',\n",
       " 'backbone.RN50model.layer3.3.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.3.conv3.weight',\n",
       " 'backbone.RN50model.layer3.3.bn3.weight',\n",
       " 'backbone.RN50model.layer3.3.bn3.bias',\n",
       " 'backbone.RN50model.layer3.3.bn3.running_mean',\n",
       " 'backbone.RN50model.layer3.3.bn3.running_var',\n",
       " 'backbone.RN50model.layer3.3.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.4.conv1.weight',\n",
       " 'backbone.RN50model.layer3.4.bn1.weight',\n",
       " 'backbone.RN50model.layer3.4.bn1.bias',\n",
       " 'backbone.RN50model.layer3.4.bn1.running_mean',\n",
       " 'backbone.RN50model.layer3.4.bn1.running_var',\n",
       " 'backbone.RN50model.layer3.4.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.4.conv2.weight',\n",
       " 'backbone.RN50model.layer3.4.bn2.weight',\n",
       " 'backbone.RN50model.layer3.4.bn2.bias',\n",
       " 'backbone.RN50model.layer3.4.bn2.running_mean',\n",
       " 'backbone.RN50model.layer3.4.bn2.running_var',\n",
       " 'backbone.RN50model.layer3.4.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.4.conv3.weight',\n",
       " 'backbone.RN50model.layer3.4.bn3.weight',\n",
       " 'backbone.RN50model.layer3.4.bn3.bias',\n",
       " 'backbone.RN50model.layer3.4.bn3.running_mean',\n",
       " 'backbone.RN50model.layer3.4.bn3.running_var',\n",
       " 'backbone.RN50model.layer3.4.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.5.conv1.weight',\n",
       " 'backbone.RN50model.layer3.5.bn1.weight',\n",
       " 'backbone.RN50model.layer3.5.bn1.bias',\n",
       " 'backbone.RN50model.layer3.5.bn1.running_mean',\n",
       " 'backbone.RN50model.layer3.5.bn1.running_var',\n",
       " 'backbone.RN50model.layer3.5.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.5.conv2.weight',\n",
       " 'backbone.RN50model.layer3.5.bn2.weight',\n",
       " 'backbone.RN50model.layer3.5.bn2.bias',\n",
       " 'backbone.RN50model.layer3.5.bn2.running_mean',\n",
       " 'backbone.RN50model.layer3.5.bn2.running_var',\n",
       " 'backbone.RN50model.layer3.5.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer3.5.conv3.weight',\n",
       " 'backbone.RN50model.layer3.5.bn3.weight',\n",
       " 'backbone.RN50model.layer3.5.bn3.bias',\n",
       " 'backbone.RN50model.layer3.5.bn3.running_mean',\n",
       " 'backbone.RN50model.layer3.5.bn3.running_var',\n",
       " 'backbone.RN50model.layer3.5.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.0.conv1.weight',\n",
       " 'backbone.RN50model.layer4.0.bn1.weight',\n",
       " 'backbone.RN50model.layer4.0.bn1.bias',\n",
       " 'backbone.RN50model.layer4.0.bn1.running_mean',\n",
       " 'backbone.RN50model.layer4.0.bn1.running_var',\n",
       " 'backbone.RN50model.layer4.0.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.0.conv2.weight',\n",
       " 'backbone.RN50model.layer4.0.bn2.weight',\n",
       " 'backbone.RN50model.layer4.0.bn2.bias',\n",
       " 'backbone.RN50model.layer4.0.bn2.running_mean',\n",
       " 'backbone.RN50model.layer4.0.bn2.running_var',\n",
       " 'backbone.RN50model.layer4.0.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.0.conv3.weight',\n",
       " 'backbone.RN50model.layer4.0.bn3.weight',\n",
       " 'backbone.RN50model.layer4.0.bn3.bias',\n",
       " 'backbone.RN50model.layer4.0.bn3.running_mean',\n",
       " 'backbone.RN50model.layer4.0.bn3.running_var',\n",
       " 'backbone.RN50model.layer4.0.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.0.downsample.0.weight',\n",
       " 'backbone.RN50model.layer4.0.downsample.1.weight',\n",
       " 'backbone.RN50model.layer4.0.downsample.1.bias',\n",
       " 'backbone.RN50model.layer4.0.downsample.1.running_mean',\n",
       " 'backbone.RN50model.layer4.0.downsample.1.running_var',\n",
       " 'backbone.RN50model.layer4.0.downsample.1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.1.conv1.weight',\n",
       " 'backbone.RN50model.layer4.1.bn1.weight',\n",
       " 'backbone.RN50model.layer4.1.bn1.bias',\n",
       " 'backbone.RN50model.layer4.1.bn1.running_mean',\n",
       " 'backbone.RN50model.layer4.1.bn1.running_var',\n",
       " 'backbone.RN50model.layer4.1.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.1.conv2.weight',\n",
       " 'backbone.RN50model.layer4.1.bn2.weight',\n",
       " 'backbone.RN50model.layer4.1.bn2.bias',\n",
       " 'backbone.RN50model.layer4.1.bn2.running_mean',\n",
       " 'backbone.RN50model.layer4.1.bn2.running_var',\n",
       " 'backbone.RN50model.layer4.1.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.1.conv3.weight',\n",
       " 'backbone.RN50model.layer4.1.bn3.weight',\n",
       " 'backbone.RN50model.layer4.1.bn3.bias',\n",
       " 'backbone.RN50model.layer4.1.bn3.running_mean',\n",
       " 'backbone.RN50model.layer4.1.bn3.running_var',\n",
       " 'backbone.RN50model.layer4.1.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.2.conv1.weight',\n",
       " 'backbone.RN50model.layer4.2.bn1.weight',\n",
       " 'backbone.RN50model.layer4.2.bn1.bias',\n",
       " 'backbone.RN50model.layer4.2.bn1.running_mean',\n",
       " 'backbone.RN50model.layer4.2.bn1.running_var',\n",
       " 'backbone.RN50model.layer4.2.bn1.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.2.conv2.weight',\n",
       " 'backbone.RN50model.layer4.2.bn2.weight',\n",
       " 'backbone.RN50model.layer4.2.bn2.bias',\n",
       " 'backbone.RN50model.layer4.2.bn2.running_mean',\n",
       " 'backbone.RN50model.layer4.2.bn2.running_var',\n",
       " 'backbone.RN50model.layer4.2.bn2.num_batches_tracked',\n",
       " 'backbone.RN50model.layer4.2.conv3.weight',\n",
       " 'backbone.RN50model.layer4.2.bn3.weight',\n",
       " 'backbone.RN50model.layer4.2.bn3.bias',\n",
       " 'backbone.RN50model.layer4.2.bn3.running_mean',\n",
       " 'backbone.RN50model.layer4.2.bn3.running_var',\n",
       " 'backbone.RN50model.layer4.2.bn3.num_batches_tracked',\n",
       " 'backbone.RN50model.fc.weight',\n",
       " 'backbone.RN50model.fc.bias',\n",
       " 'projector.layers.0.weight',\n",
       " 'projector.layers.0.bias',\n",
       " 'projector.layers.1.weight',\n",
       " 'projector.layers.1.bias',\n",
       " 'projector.layers.1.running_mean',\n",
       " 'projector.layers.1.running_var',\n",
       " 'projector.layers.1.num_batches_tracked',\n",
       " 'projector.layers.3.weight',\n",
       " 'projector.layers.3.bias',\n",
       " 'classifier.classifier.weight',\n",
       " 'classifier.classifier.bias']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(ckpt_file, map_location=\"cpu\")\n",
    "list(ckpt[\"state_dict\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from /workspaces/HIAAC-KR-Dev-Container/shared_data/notebooks_e_pesos/pesos/simclr.ckpt\n",
      "When loading model, the following keys are missing: ['fc.0.convs.0.0.weight', 'fc.0.convs.0.1.weight', 'fc.0.convs.0.1.bias', 'fc.0.convs.0.1.running_mean', 'fc.0.convs.0.1.running_var', 'fc.0.convs.1.0.weight', 'fc.0.convs.1.1.weight', 'fc.0.convs.1.1.bias', 'fc.0.convs.1.1.running_mean', 'fc.0.convs.1.1.running_var', 'fc.0.convs.2.0.weight', 'fc.0.convs.2.1.weight', 'fc.0.convs.2.1.bias', 'fc.0.convs.2.1.running_mean', 'fc.0.convs.2.1.running_var', 'fc.0.convs.3.0.weight', 'fc.0.convs.3.1.weight', 'fc.0.convs.3.1.bias', 'fc.0.convs.3.1.running_mean', 'fc.0.convs.3.1.running_var', 'fc.0.convs.4.1.weight', 'fc.0.convs.4.2.weight', 'fc.0.convs.4.2.bias', 'fc.0.convs.4.2.running_mean', 'fc.0.convs.4.2.running_var', 'fc.0.project.0.weight', 'fc.0.project.1.weight', 'fc.0.project.1.bias', 'fc.0.project.1.running_mean', 'fc.0.project.1.running_var', 'fc.1.weight', 'fc.2.weight', 'fc.2.bias', 'fc.2.running_mean', 'fc.2.running_var', 'fc.4.weight', 'fc.4.bias']\n"
     ]
    }
   ],
   "source": [
    "from minerva.models.loaders import FromPretrained\n",
    "\n",
    "model = FromPretrained(\n",
    "    model,\n",
    "    ckpt_path=ckpt_file,\n",
    "    strict=False,\n",
    "    filter_keys=[\"^backbone.RN50model.\"],\n",
    "    error_on_missing_keys=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log directory set to: /workspaces/HIAAC-KR-Dev-Container/Minerva-Dev/docs/notebooks/examples/seismic/facies_classification/parihaka/logs/simclr/seam_ai\n"
     ]
    }
   ],
   "source": [
    "pipeline = get_trainer_pipeline(\n",
    "    model=model,\n",
    "    model_name=model_name,\n",
    "    dataset_name=dataset_name,\n",
    "    log_dir=log_dir,\n",
    "    num_epochs=num_epochs,\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    is_debug=is_debug,\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/fabric/loggers/csv_logs.py:268: Experiment logs directory ./logs/simclr/seam_ai exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Dev/docs/notebooks/examples/seismic/facies_classification/parihaka/logs/simclr/seam_ai/run_2024-12-19-18-37-46a5460df9e70b49bb8d2bbd640c62a96c.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type                    | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | backbone | DeepLabV3Backbone       | 25.6 M | train\n",
      "1 | fc       | DeepLabV3PredictionHead | 16.1 M | train\n",
      "2 | loss_fn  | CrossEntropyLoss        | 0      | train\n",
      "-------------------------------------------------------------\n",
      "41.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "41.7 M    Total params\n",
      "166.736   Total estimated model params size (MB)\n",
      "186       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|| 3/3 [00:01<00:00,  2.70it/s, v_num=m_ai, val_loss=7.540, train_loss=1.020]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|| 3/3 [00:14<00:00,  0.21it/s, v_num=m_ai, val_loss=7.540, train_loss=1.020]\n",
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Dev/docs/notebooks/examples/seismic/facies_classification/parihaka/logs/simclr/seam_ai/run_2024-12-19-18-37-46a5460df9e70b49bb8d2bbd640c62a96c.yaml\n"
     ]
    }
   ],
   "source": [
    "pipeline.run(data_module, task=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at ./logs/simclr/seam_ai/checkpoints/last.ckpt\n"
     ]
    }
   ],
   "source": [
    "print(f\"Checkpoint saved at {pipeline.trainer.checkpoint_callback.last_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
