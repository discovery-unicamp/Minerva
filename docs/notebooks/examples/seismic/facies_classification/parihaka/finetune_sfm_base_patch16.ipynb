{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tunning SFM Base Patch16 on Parihaka Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:54: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from common import get_data_module, get_trainer_pipeline\n",
    "import torch\n",
    "from minerva.models.nets.image.vit import SFM_BasePatch16_Downstream\n",
    "from functools import partial\n",
    "from minerva.models.loaders import FromPretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_dir = \"/workspaces/HIAAC-KR-Dev-Container/shared_data/seam_ai_datasets/seam_ai/images\"\n",
    "root_annotation_dir = \"/workspaces/HIAAC-KR-Dev-Container/shared_data/seam_ai_datasets/seam_ai/annotations\"\n",
    "img_size = (512, 512)          # Change this to the size of the images in the dataset\n",
    "model_name = \"sfm-base-patch16\"       # Model name (just identifier)\n",
    "dataset_name = \"seam_ai\"        # Dataset name (just identifier)\n",
    "single_channel = True          # If True, the model will be trained with single channel images (instead of 3 channels)\n",
    "\n",
    "log_dir = \"./logs\"              # Directory to save logs\n",
    "batch_size = 1                  # Batch size    \n",
    "seed = 42                       # Seed for reproducibility\n",
    "num_epochs = 100                # Number of epochs to train\n",
    "is_debug = True                 # If True, only 3 batch will be processed for 3 epochs\n",
    "accelerator = \"gpu\"             # CPU or GPU\n",
    "devices = 1                     # Num GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataModule\n",
       "    Data: /workspaces/HIAAC-KR-Dev-Container/shared_data/seam_ai_datasets/seam_ai/images\n",
       "    Annotations: /workspaces/HIAAC-KR-Dev-Container/shared_data/seam_ai_datasets/seam_ai/annotations\n",
       "    Batch size: 1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = get_data_module(\n",
    "    root_data_dir=root_data_dir,\n",
    "    root_annotation_dir=root_annotation_dir,\n",
    "    img_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    seed=seed,\n",
    "    single_channel=single_channel, \n",
    ")\n",
    "\n",
    "data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 512, 512]), torch.Size([1, 1, 512, 512]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to check if the data module is working\n",
    "data_module.setup(\"fit\")\n",
    "train_batch_x, train_batch_y = next(iter(data_module.train_dataloader()))\n",
    "train_batch_x.shape, train_batch_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **** Create and Load model HERE ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SFM_BasePatch16_Downstream(\n",
       "  (backbone): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Linear(in_features=768, out_features=6, bias=True)\n",
       "    (decoder): VIT_MLAHead(\n",
       "      (mlahead): MLAHead(\n",
       "        (head2): Sequential(\n",
       "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "        (head3): Sequential(\n",
       "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "        (head4): Sequential(\n",
       "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "        (head5): Sequential(\n",
       "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (cls): Conv2d(512, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (segmentation_head): SegmentationHead(\n",
       "      (0): Conv2d(16, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Identity()\n",
       "    )\n",
       "    (loss_fn): CrossEntropyLoss()\n",
       "  )\n",
       "  (fc): Identity()\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SFM_BasePatch16_Downstream(\n",
    "    img_size=(512, 512),\n",
    "    num_classes=6,\n",
    "    in_chans=1\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing key renaming with: {'': 'backbone.'}\n",
      "\tRenaming key: cls_token -> backbone.cls_token (changed: True)\n",
      "\tRenaming key: pos_embed -> backbone.pos_embed (changed: True)\n",
      "\tRenaming key: patch_embed.proj.weight -> backbone.patch_embed.proj.weight (changed: True)\n",
      "\tRenaming key: patch_embed.proj.bias -> backbone.patch_embed.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.0.norm1.weight -> backbone.blocks.0.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.0.norm1.bias -> backbone.blocks.0.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.0.attn.qkv.weight -> backbone.blocks.0.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.0.attn.qkv.bias -> backbone.blocks.0.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.0.attn.proj.weight -> backbone.blocks.0.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.0.attn.proj.bias -> backbone.blocks.0.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.0.norm2.weight -> backbone.blocks.0.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.0.norm2.bias -> backbone.blocks.0.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.0.mlp.fc1.weight -> backbone.blocks.0.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.0.mlp.fc1.bias -> backbone.blocks.0.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.0.mlp.fc2.weight -> backbone.blocks.0.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.0.mlp.fc2.bias -> backbone.blocks.0.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.1.norm1.weight -> backbone.blocks.1.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.1.norm1.bias -> backbone.blocks.1.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.1.attn.qkv.weight -> backbone.blocks.1.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.1.attn.qkv.bias -> backbone.blocks.1.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.1.attn.proj.weight -> backbone.blocks.1.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.1.attn.proj.bias -> backbone.blocks.1.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.1.norm2.weight -> backbone.blocks.1.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.1.norm2.bias -> backbone.blocks.1.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.1.mlp.fc1.weight -> backbone.blocks.1.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.1.mlp.fc1.bias -> backbone.blocks.1.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.1.mlp.fc2.weight -> backbone.blocks.1.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.1.mlp.fc2.bias -> backbone.blocks.1.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.2.norm1.weight -> backbone.blocks.2.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.2.norm1.bias -> backbone.blocks.2.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.2.attn.qkv.weight -> backbone.blocks.2.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.2.attn.qkv.bias -> backbone.blocks.2.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.2.attn.proj.weight -> backbone.blocks.2.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.2.attn.proj.bias -> backbone.blocks.2.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.2.norm2.weight -> backbone.blocks.2.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.2.norm2.bias -> backbone.blocks.2.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.2.mlp.fc1.weight -> backbone.blocks.2.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.2.mlp.fc1.bias -> backbone.blocks.2.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.2.mlp.fc2.weight -> backbone.blocks.2.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.2.mlp.fc2.bias -> backbone.blocks.2.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.3.norm1.weight -> backbone.blocks.3.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.3.norm1.bias -> backbone.blocks.3.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.3.attn.qkv.weight -> backbone.blocks.3.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.3.attn.qkv.bias -> backbone.blocks.3.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.3.attn.proj.weight -> backbone.blocks.3.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.3.attn.proj.bias -> backbone.blocks.3.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.3.norm2.weight -> backbone.blocks.3.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.3.norm2.bias -> backbone.blocks.3.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.3.mlp.fc1.weight -> backbone.blocks.3.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.3.mlp.fc1.bias -> backbone.blocks.3.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.3.mlp.fc2.weight -> backbone.blocks.3.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.3.mlp.fc2.bias -> backbone.blocks.3.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.4.norm1.weight -> backbone.blocks.4.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.4.norm1.bias -> backbone.blocks.4.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.4.attn.qkv.weight -> backbone.blocks.4.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.4.attn.qkv.bias -> backbone.blocks.4.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.4.attn.proj.weight -> backbone.blocks.4.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.4.attn.proj.bias -> backbone.blocks.4.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.4.norm2.weight -> backbone.blocks.4.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.4.norm2.bias -> backbone.blocks.4.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.4.mlp.fc1.weight -> backbone.blocks.4.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.4.mlp.fc1.bias -> backbone.blocks.4.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.4.mlp.fc2.weight -> backbone.blocks.4.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.4.mlp.fc2.bias -> backbone.blocks.4.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.5.norm1.weight -> backbone.blocks.5.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.5.norm1.bias -> backbone.blocks.5.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.5.attn.qkv.weight -> backbone.blocks.5.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.5.attn.qkv.bias -> backbone.blocks.5.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.5.attn.proj.weight -> backbone.blocks.5.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.5.attn.proj.bias -> backbone.blocks.5.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.5.norm2.weight -> backbone.blocks.5.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.5.norm2.bias -> backbone.blocks.5.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.5.mlp.fc1.weight -> backbone.blocks.5.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.5.mlp.fc1.bias -> backbone.blocks.5.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.5.mlp.fc2.weight -> backbone.blocks.5.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.5.mlp.fc2.bias -> backbone.blocks.5.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.6.norm1.weight -> backbone.blocks.6.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.6.norm1.bias -> backbone.blocks.6.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.6.attn.qkv.weight -> backbone.blocks.6.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.6.attn.qkv.bias -> backbone.blocks.6.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.6.attn.proj.weight -> backbone.blocks.6.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.6.attn.proj.bias -> backbone.blocks.6.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.6.norm2.weight -> backbone.blocks.6.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.6.norm2.bias -> backbone.blocks.6.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.6.mlp.fc1.weight -> backbone.blocks.6.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.6.mlp.fc1.bias -> backbone.blocks.6.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.6.mlp.fc2.weight -> backbone.blocks.6.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.6.mlp.fc2.bias -> backbone.blocks.6.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.7.norm1.weight -> backbone.blocks.7.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.7.norm1.bias -> backbone.blocks.7.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.7.attn.qkv.weight -> backbone.blocks.7.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.7.attn.qkv.bias -> backbone.blocks.7.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.7.attn.proj.weight -> backbone.blocks.7.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.7.attn.proj.bias -> backbone.blocks.7.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.7.norm2.weight -> backbone.blocks.7.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.7.norm2.bias -> backbone.blocks.7.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.7.mlp.fc1.weight -> backbone.blocks.7.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.7.mlp.fc1.bias -> backbone.blocks.7.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.7.mlp.fc2.weight -> backbone.blocks.7.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.7.mlp.fc2.bias -> backbone.blocks.7.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.8.norm1.weight -> backbone.blocks.8.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.8.norm1.bias -> backbone.blocks.8.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.8.attn.qkv.weight -> backbone.blocks.8.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.8.attn.qkv.bias -> backbone.blocks.8.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.8.attn.proj.weight -> backbone.blocks.8.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.8.attn.proj.bias -> backbone.blocks.8.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.8.norm2.weight -> backbone.blocks.8.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.8.norm2.bias -> backbone.blocks.8.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.8.mlp.fc1.weight -> backbone.blocks.8.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.8.mlp.fc1.bias -> backbone.blocks.8.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.8.mlp.fc2.weight -> backbone.blocks.8.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.8.mlp.fc2.bias -> backbone.blocks.8.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.9.norm1.weight -> backbone.blocks.9.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.9.norm1.bias -> backbone.blocks.9.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.9.attn.qkv.weight -> backbone.blocks.9.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.9.attn.qkv.bias -> backbone.blocks.9.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.9.attn.proj.weight -> backbone.blocks.9.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.9.attn.proj.bias -> backbone.blocks.9.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.9.norm2.weight -> backbone.blocks.9.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.9.norm2.bias -> backbone.blocks.9.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.9.mlp.fc1.weight -> backbone.blocks.9.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.9.mlp.fc1.bias -> backbone.blocks.9.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.9.mlp.fc2.weight -> backbone.blocks.9.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.9.mlp.fc2.bias -> backbone.blocks.9.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.10.norm1.weight -> backbone.blocks.10.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.10.norm1.bias -> backbone.blocks.10.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.10.attn.qkv.weight -> backbone.blocks.10.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.10.attn.qkv.bias -> backbone.blocks.10.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.10.attn.proj.weight -> backbone.blocks.10.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.10.attn.proj.bias -> backbone.blocks.10.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.10.norm2.weight -> backbone.blocks.10.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.10.norm2.bias -> backbone.blocks.10.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.10.mlp.fc1.weight -> backbone.blocks.10.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.10.mlp.fc1.bias -> backbone.blocks.10.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.10.mlp.fc2.weight -> backbone.blocks.10.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.10.mlp.fc2.bias -> backbone.blocks.10.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: blocks.11.norm1.weight -> backbone.blocks.11.norm1.weight (changed: True)\n",
      "\tRenaming key: blocks.11.norm1.bias -> backbone.blocks.11.norm1.bias (changed: True)\n",
      "\tRenaming key: blocks.11.attn.qkv.weight -> backbone.blocks.11.attn.qkv.weight (changed: True)\n",
      "\tRenaming key: blocks.11.attn.qkv.bias -> backbone.blocks.11.attn.qkv.bias (changed: True)\n",
      "\tRenaming key: blocks.11.attn.proj.weight -> backbone.blocks.11.attn.proj.weight (changed: True)\n",
      "\tRenaming key: blocks.11.attn.proj.bias -> backbone.blocks.11.attn.proj.bias (changed: True)\n",
      "\tRenaming key: blocks.11.norm2.weight -> backbone.blocks.11.norm2.weight (changed: True)\n",
      "\tRenaming key: blocks.11.norm2.bias -> backbone.blocks.11.norm2.bias (changed: True)\n",
      "\tRenaming key: blocks.11.mlp.fc1.weight -> backbone.blocks.11.mlp.fc1.weight (changed: True)\n",
      "\tRenaming key: blocks.11.mlp.fc1.bias -> backbone.blocks.11.mlp.fc1.bias (changed: True)\n",
      "\tRenaming key: blocks.11.mlp.fc2.weight -> backbone.blocks.11.mlp.fc2.weight (changed: True)\n",
      "\tRenaming key: blocks.11.mlp.fc2.bias -> backbone.blocks.11.mlp.fc2.bias (changed: True)\n",
      "\tRenaming key: norm.weight -> backbone.norm.weight (changed: True)\n",
      "\tRenaming key: norm.bias -> backbone.norm.bias (changed: True)\n",
      "Model loaded from /workspaces/HIAAC-KR-Dev-Container/shared_data/seismic_foundation_model/pretrained_models/SFM-Base-512.pth\n",
      "When loading model, the following keys are missing: ['backbone.head.weight', 'backbone.head.bias', 'backbone.decoder.mlahead.head2.0.weight', 'backbone.decoder.mlahead.head2.1.weight', 'backbone.decoder.mlahead.head2.1.bias', 'backbone.decoder.mlahead.head2.1.running_mean', 'backbone.decoder.mlahead.head2.1.running_var', 'backbone.decoder.mlahead.head2.3.weight', 'backbone.decoder.mlahead.head2.4.weight', 'backbone.decoder.mlahead.head2.4.bias', 'backbone.decoder.mlahead.head2.4.running_mean', 'backbone.decoder.mlahead.head2.4.running_var', 'backbone.decoder.mlahead.head3.0.weight', 'backbone.decoder.mlahead.head3.1.weight', 'backbone.decoder.mlahead.head3.1.bias', 'backbone.decoder.mlahead.head3.1.running_mean', 'backbone.decoder.mlahead.head3.1.running_var', 'backbone.decoder.mlahead.head3.3.weight', 'backbone.decoder.mlahead.head3.4.weight', 'backbone.decoder.mlahead.head3.4.bias', 'backbone.decoder.mlahead.head3.4.running_mean', 'backbone.decoder.mlahead.head3.4.running_var', 'backbone.decoder.mlahead.head4.0.weight', 'backbone.decoder.mlahead.head4.1.weight', 'backbone.decoder.mlahead.head4.1.bias', 'backbone.decoder.mlahead.head4.1.running_mean', 'backbone.decoder.mlahead.head4.1.running_var', 'backbone.decoder.mlahead.head4.3.weight', 'backbone.decoder.mlahead.head4.4.weight', 'backbone.decoder.mlahead.head4.4.bias', 'backbone.decoder.mlahead.head4.4.running_mean', 'backbone.decoder.mlahead.head4.4.running_var', 'backbone.decoder.mlahead.head5.0.weight', 'backbone.decoder.mlahead.head5.1.weight', 'backbone.decoder.mlahead.head5.1.bias', 'backbone.decoder.mlahead.head5.1.running_mean', 'backbone.decoder.mlahead.head5.1.running_var', 'backbone.decoder.mlahead.head5.3.weight', 'backbone.decoder.mlahead.head5.4.weight', 'backbone.decoder.mlahead.head5.4.bias', 'backbone.decoder.mlahead.head5.4.running_mean', 'backbone.decoder.mlahead.head5.4.running_var', 'backbone.decoder.cls.weight', 'backbone.decoder.cls.bias', 'backbone.segmentation_head.0.weight', 'backbone.segmentation_head.0.bias']\n"
     ]
    }
   ],
   "source": [
    "model = FromPretrained(\n",
    "    model=model,\n",
    "    ckpt_path=\"/workspaces/HIAAC-KR-Dev-Container/shared_data/seismic_foundation_model/pretrained_models/SFM-Base-512.pth\",\n",
    "    ckpt_key=\"model\",\n",
    "    strict=False,\n",
    "    filter_keys=[\"^blocks*\", \"^cls_token\", \"^pos_embed\", \"^patch_embed\", \"^norm\"],\n",
    "    keys_to_rename={\"\": \"backbone.\"},\n",
    "    ckpt_load_weights_only=False,\n",
    "    error_on_missing_keys=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log directory set to: /workspaces/HIAAC-KR-Dev-Container/Minerva-Dev/docs/notebooks/examples/seismic/facies_classification/parihaka/logs/sfm-base-patch16/seam_ai\n"
     ]
    }
   ],
   "source": [
    "pipeline = get_trainer_pipeline(\n",
    "    model=model,\n",
    "    model_name=model_name,\n",
    "    dataset_name=dataset_name,\n",
    "    log_dir=log_dir,\n",
    "    num_epochs=num_epochs,\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    is_debug=is_debug,\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/fabric/loggers/csv_logs.py:268: Experiment logs directory ./logs/sfm-base-patch16/seam_ai exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Dev/docs/notebooks/examples/seismic/facies_classification/parihaka/logs/sfm-base-patch16/seam_ai/run_2024-12-06-14-24-03cc37a68a1cb74db7b8866e7e11eb966d.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory ./logs/sfm-base-patch16/seam_ai/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type              | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | backbone | VisionTransformer | 90.2 M | train\n",
      "1 | fc       | Identity          | 0      | train\n",
      "2 | loss_fn  | CrossEntropyLoss  | 0      | train\n",
      "-------------------------------------------------------\n",
      "90.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "90.2 M    Total params\n",
      "360.821   Total estimated model params size (MB)\n",
      "301       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3/3 [00:00<00:00,  4.39it/s, v_num=m_ai, val_loss=3.670, train_loss=1.320]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 3/3 [00:45<00:00,  0.07it/s, v_num=m_ai, val_loss=3.670, train_loss=1.320]\n",
      "Pipeline info saved at: /workspaces/HIAAC-KR-Dev-Container/Minerva-Dev/docs/notebooks/examples/seismic/facies_classification/parihaka/logs/sfm-base-patch16/seam_ai/run_2024-12-06-14-24-03cc37a68a1cb74db7b8866e7e11eb966d.yaml\n"
     ]
    }
   ],
   "source": [
    "pipeline.run(data_module, task=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved at ./logs/sfm-base-patch16/seam_ai/checkpoints/last-v2.ckpt\n"
     ]
    }
   ],
   "source": [
    "print(f\"Checkpoint saved at {pipeline.trainer.checkpoint_callback.last_model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
