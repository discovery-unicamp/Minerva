{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "Pipelines provide a versatile API for automating tasks efficiently. Below some key features and best practices:\n",
    "\n",
    "## 1. Reproducibility\n",
    "\n",
    "- **Initialization and Configuration**: Pipelines are initialized using the `__init__` method, allowing configuration of common elements. All parameters passed to the class constructor are stored in the `self.hparams` dictionary, facilitating reproducibility and serialization. Additionally, the `ignore` parameter in the `__init__` method allows exclusion of specific parameters, enhancing reproducibility by avoiding the storage of non-essential or large parameters. For example:\n",
    "\n",
    "    ```python\n",
    "    pipeline = Pipeline(ignore=[\"large_param\"])\n",
    "    ```\n",
    "\n",
    "- **ID and Working Directory**: Each pipeline instance is assigned a unique identifier (`id`) upon initialization, aiding in tracking and identification. Additionally, pipelines have a designated working directory for organizing generated files, though it doesn't alter Python's working directory. Example:\n",
    "\n",
    "    ```python\n",
    "    print(f\"Pipeline ID: {pipeline.pipeline_id}\")\n",
    "    print(f\"Working Directory: {pipeline.working_dir}\")\n",
    "    ```\n",
    "\n",
    "- **Public Interface**: Pipelines offer the `run` method as the public interface for execution. The `run` method encapsulates the pipeline's logic and returns the output. Note that, `run` is the only method that should be called directly by users. For your own version of pipeline, you should override `_run` method (that is called from `run`) Example:\n",
    "\n",
    "    ```python\n",
    "    result = pipeline.run(argument=value)\n",
    "    ```\n",
    "    \n",
    "    Besides a result, the `run` method can also set public attributes of the pipeline instance. These attributes are implemented as read-only properties, ensuring a consistent state during execution. For instance, the code below:\n",
    "\n",
    "    ```python\n",
    "    class Example(Pipeline):\n",
    "        def __init__(self, start=0, end=100):\n",
    "            # Cache result allows to maintain the return of `run` method at `_result` attribute\n",
    "            # This can be accessed though the `result` property (public attribute)\n",
    "            super().__init__(cache_result=True)\n",
    "            self._seed = None\n",
    "            self._start = start\n",
    "            self._end = end\n",
    "\n",
    "        # Read-only, public attribute (properties)\n",
    "        # This attribute is set during pipeline execution and can be accessed before and after execution.\n",
    "        # ONly these attributes (properties) and the _run method should be accessed directly by users.\n",
    "        @property\n",
    "        def seed(self):\n",
    "            return self._seed\n",
    "\n",
    "        def _run(self, argument):\n",
    "            # Pipeline logic here\n",
    "\n",
    "            # Set seed attribute.\n",
    "            self._seed = int(time.time())\n",
    "            np.random.seed(self._seed)\n",
    "            return np.random.randint(self._start, self._end) + argument\n",
    "\n",
    "\n",
    "    pipeline = Example()\n",
    "\n",
    "    print(pipeline.hparams)\n",
    "    # Output: {'start': 0, 'end': 100}\n",
    "\n",
    "    print(pipeline.status)\n",
    "    #{'status': 'NOT STARTED',\n",
    "    #  'working_dir': '/workspaces/seismic',\n",
    "    #  'id': 'ae87a62731c04604bb35c0b9d4626982',\n",
    "    #  'count': 0,\n",
    "    #  'created': 1715128966.1678915,\n",
    "    #  'start_time': None,\n",
    "    #  'end_time': None,\n",
    "    #  'exception_info': None,\n",
    "    #  'cached': False}\n",
    "\n",
    "    result = pipeline.run(argument=10)\n",
    "    print(result)\n",
    "    # Output: 91\n",
    "\n",
    "    print(pipeline.result)\n",
    "    # Output: 91\n",
    "    ```\n",
    "\n",
    "    The public attributes are `seed` that is set during the pipeline run.\n",
    "\n",
    "\n",
    "## 2. Composition\n",
    "\n",
    "- **Combining Pipelines**: Pipelines can be composed of other pipelines, allowing the creation of complex workflows from simpler components. This modularity enhances flexibility and scalability in pipeline design.\n",
    "\n",
    "For instance, consider the minimal example following example:\n",
    "\n",
    "```python\n",
    "\n",
    "class Distance(Pipeline):\n",
    "    def __init__(self, norm: int):\n",
    "        super().__init__(cache_result=False)\n",
    "        self.norm = norm\n",
    "\n",
    "    def _run(self, x, y):\n",
    "        return (x**self.norm + y**self.norm) ** (1 / self.norm)\n",
    "\n",
    "\n",
    "class SumOfDistances(Pipeline):\n",
    "    def __init__(self, constant: int, distance_pipeline: Distance):\n",
    "        super().__init__(ignore=\"distance_pipeline\", cache_result=True)\n",
    "        self.constant = constant\n",
    "        self.distance_pipeline = distance_pipeline\n",
    "\n",
    "    def _run(self, items: List[Tuple[float, float]]):\n",
    "        return (\n",
    "            sum(self.distance_pipeline.run(x, y) for x, y in items)\n",
    "            + self.constant\n",
    "        )\n",
    "```\n",
    "\n",
    "In this example, we have two pipelines: `Distance` and `SumOfDistances`. The `Distance` pipeline calculates the distance between two points based on a specified norm. The `SumOfDistances` pipeline calculates the sum of distances between multiple points and adds a constant value. The `SumOfDistances` pipeline uses the `Distance` pipeline as a component, demonstrating pipeline composition.\n",
    "\n",
    "```python\n",
    "distance_pipeline = Distance(norm=2)\n",
    "sum_of_distances_pipeline = SumOfDistances(constant=10, distance_pipeline=distance_pipeline)\n",
    "sum_of_distances_pipeline.run([(1, 2), (3, 4),(5, 6)])\n",
    "# Output: 25.046317653406444\n",
    "```\n",
    "\n",
    "\n",
    "## 3. Integration with CLI\n",
    "\n",
    "- **Seamless CLI Integration**: Pipelines integrate seamlessly with `jsonargparse`, enabling the creation of command-line interfaces (CLI) for easy configuration and execution. Configuration can be provided via YAML files or directly through CLI run arguments, enhancing user accessibility. Examples of CLI usage with `jsonargparse` are provided. For instance, we can use the `CLI` class to run a pipeline with arguments:\n",
    "\n",
    "    ```python\n",
    "    # Example CLI usage\n",
    "    args = [\n",
    "        \"--constant\",\n",
    "        \"10\",\n",
    "        \"--distance_pipeline\",\n",
    "        '{\"class_path\": \"Distance\", \"init_args\": {\"norm\": \"2\"}}',\n",
    "        \"run\",\n",
    "        \"--items\",\n",
    "        '[[\"1\", \"2\"], [\"3\", \"4\"], [\"5\", \"6\"]]',\n",
    "    ]\n",
    "\n",
    "    result = CLI(SumOfDistances, as_positional=False, args=args)\n",
    "\n",
    "    ```\n",
    "\n",
    "\n",
    "Or write an YAML file for some of the parameters\n",
    "\n",
    "```yaml\n",
    "# config.yaml\n",
    "constant: 10\n",
    "distance_pipeline:\n",
    "  class_path: Distance\n",
    "  init_args:\n",
    "    norm: 2\n",
    "```\n",
    "\n",
    "And run the pipeline with the YAML file:\n",
    "\n",
    "```python\n",
    "# Example CLI usage with YAML file\n",
    "result = CLI(SumOfDistances, as_positional=False, args=[\"--config\", \"config.yaml\", \"run\", \"--items\", '[[\"1\", \"2\"], [\"3\", \"4\"], [\"5\", \"6\"]]'])\n",
    "```\n",
    "\n",
    "Or write an YAML file for all the parameters\n",
    "\n",
    "```yaml\n",
    "# config.yaml\n",
    "constant: 10\n",
    "distance_pipeline:\n",
    "  class_path: Distance\n",
    "  init_args:\n",
    "    norm: 2\n",
    "run:\n",
    "  items:\n",
    "    - [1, 2]\n",
    "    - [3, 4]\n",
    "    - [5, 6]\n",
    "```\n",
    "\n",
    "And run the pipeline with the YAML file:\n",
    "\n",
    "```python\n",
    "# Example CLI usage with YAML file\n",
    "result = CLI(SumOfDistances, as_positional=False, args=[\"--config\", \"config.yaml\"])\n",
    "```\n",
    "\n",
    "And we can run from shell:\n",
    "    \n",
    "```bash\n",
    "    python script.py --constant 10 --distance_pipeline '{\"class_path\": \"Distance\", \"init_args\": {\"norm\": \"2\"}}' run --items '[[\"1\", \"2\"], [\"3\", \"4\"], [\"5\", \"6\"]]'\n",
    "```\n",
    "\n",
    "Or the YAML file:\n",
    "\n",
    "```bash\n",
    "    python script.py --config config.yaml\n",
    "```\n",
    "\n",
    "\n",
    "## 4. Logging and Monitoring\n",
    "\n",
    "- **Execution Log**: Pipelines maintain a log of their executions, providing a comprehensive record of activities. The `status` property offers insights into the pipeline's state, from creation to completion, facilitating monitoring and troubleshooting. Example:\n",
    "\n",
    "    ```python\n",
    "    print(f\"Pipeline Status: {pipeline.status}\")\n",
    "    ```\n",
    "\n",
    "## 5. Clonability\n",
    "\n",
    "- **Cloning Pipelines**: Pipelines are cloneable, enabling the creation of independent instances from existing ones. The `clone` method initializes a deep copy, providing a clean slate for each clone. Example:\n",
    "\n",
    "    ```python\n",
    "    cloned_pipeline = Pipeline.clone(pipeline)\n",
    "    ```\n",
    "\n",
    "Note that some attributes, such as `id`, are unique to each pipeline instance and are updated during cloning to maintain uniqueness.\n",
    "\n",
    "\n",
    "\n",
    "## 6. Parallel and Distributed Environments\n",
    "\n",
    "- **Parallel Execution**: Pipelines support parallel execution, enabling faster processing of tasks and efficient resource utilization.\n",
    "\n",
    "- **Distributed Execution**: Pipelines can be executed in a distributed manner, suitable for deployment on clusters to leverage distributed computing resources effectively. This scalability enhances performance in large-scale processing environments."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
