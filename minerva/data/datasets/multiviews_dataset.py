from typing import Any, Tuple, Sequence
from torch.utils.data import Dataset
from minerva.transforms.transform import _Transform


class MultiViewsDataset(Dataset):
    """Dataset for generating multiple views of each sample using specified
    transformation pipelines.

    This dataset wraps another dataset, applying a sequence of transformations
    to each sample to create multiple augmented versions. For each sample in
    the original dataset, a tuple of transformed samples is returned, where each
    element in the tuple is the result of one transformation pipeline.

    This class is useful in scenarios where multiple perspectives of the same data
    are needed, such as contrastive learning or general data augmentation.

    The __getitem__ pipeline is as follows:

    For each transform pipeline T:
        1. Retrieve the original data sample from the underlying dataset.
        2. Apply transformation pipeline T to the data sample.
        3. Append the transformed data to a tuple.
    Return the tuple of transformed data samples.
    """

    def __init__(
        self,
        dataset: Dataset,
        transform_pipelines: Sequence[_Transform],
    ):
        """Initialize the multi-views dataset with a base dataset and transformations.

        Parameters
        ----------
        dataset : Dataset
            The base dataset from which samples will be drawn.
        transform_pipelines : Sequence[_Transform]
            A sequence of transformations to apply to each sample. Each
            transformation pipeline generates a different view of the same data
            sample, enabling multiple perspectives on the data.
            - Each transform in the sequence will be applied to each sample
              in `dataset`, producing multiple transformed versions of that sample.

        Examples
        --------
        ```python
        from minerva.data.datasets import MultiViewsDataset
        from minerva.transforms.transform import Transpose, PerlinMasker
        from torchvision.datasets import CIFAR10

        # Load a dataset
        base_dataset = CIFAR10(root="path/to/data", download=True)

        # Define transformation pipelines
        transforms = [Transpose(2), PerlinMasker(3)]

        # Create the contrastive dataset
        contrastive_dataset = MultiViewsDataset(base_dataset, transforms)
        
        # Each __getitem__ call returns a tuple of transformed images
        sample_views = contrastive_dataset[0]  # Returns (view1, view2)
        ```
        """
        self.dataset = dataset
        self.transform_pipelines = transform_pipelines

    def __len__(self) -> int:
        """The length of the dataset is defined by the length of the base dataset.

        Returns
        -------
        int
            The number of samples in the dataset.
        """
        return len(self.dataset)

    def __getitem__(self, idx: int) -> Tuple[Any, ...]:
        """Retrieve a sample from the base dataset and apply each transform pipeline.

        Parameters
        ----------
        idx : int
            The index of the sample to load from the base dataset.

        Returns
        -------
        Tuple[Any, ...]
            A tuple of transformed versions of the sample, each generated by
            a different transformation pipeline in `transform_pipelines`.
        """
        entry = self.dataset[idx]
        return tuple(T(entry) for T in self.transform_pipelines)
